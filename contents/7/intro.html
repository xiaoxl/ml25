<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.9.9">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>7&nbsp; Netural networks – Machine Learning {{&lt; var info.date &gt;}}</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../contents/app/setup.html" rel="next">
<link href="../../contents/6/intro.html" rel="prev">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-bbfe0a5b9fb228be1b45e71d50e4f997.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-0e3b29b5fa97dc5090eff3fd9e71dcd2.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-bbfe0a5b9fb228be1b45e71d50e4f997.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-c0d2154c8f415210cf187502ecb0c845.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-abfcbbee754f2352fb90360e6f57f36e.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../site_libs/bootstrap/bootstrap-c0d2154c8f415210cf187502ecb0c845.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/quarto-contrib/bookup_fonts_gwf-0.0/fonts-embed.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar docked nav-fixed quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Machine Learning 2025 Fall</span>
    </a>
  </div>
        <div class="quarto-navbar-tools tools-end">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../contents/7/intro.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Netural networks</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/1/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/2/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">k-Nearest Neighbors algorithm (k-NN)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/3/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Decision Trees</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/4/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Ensemble methods</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/5/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Intro to Pytorch</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/6/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Logistic regression</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/7/intro.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Netural networks</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/app/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Python IDE Setup</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#neural-network-back-propagation" id="toc-neural-network-back-propagation" class="nav-link active" data-scroll-target="#neural-network-back-propagation"><span class="header-section-number">7.1</span> Neural network: Back propagation</a></li>
  <li><a href="#example" id="toc-example" class="nav-link" data-scroll-target="#example"><span class="header-section-number">7.2</span> Example</a></li>
  <li><a href="#exercises-and-projects" id="toc-exercises-and-projects" class="nav-link" data-scroll-target="#exercises-and-projects"><span class="header-section-number">7.3</span> Exercises and Projects</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Netural networks</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>There are many different architects of netural networks. In our course we will only talk about the simplest one: multilayer perceptron (MLP). We will treat it as the generalization of logistic regression. In other words, we will treat logistic regression as an one-layer netural network. Under this idea, all the concepts and ideas, like gradient descent, mini-batch training, loss functions, learning curves, etc.. will be used.</p>
<section id="neural-network-back-propagation" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="neural-network-back-propagation"><span class="header-section-number">7.1</span> Neural network: Back propagation</h2>
<div class="hidden">
<p><span class="math display">\[
\newcommand\diffp[2]{\dfrac{\partial #1}{\partial #2}}
\]</span></p>
</div>
<p>To train a MLP model, we still use gradient descent. Therefore it is very important to know how to compute the gradient. Actually the idea is the same as logistic regreesion. The only issue is that now the model is more complicated. The gradient computation is summrized as an algorithm called <code>back propagation</code>. It is described as follows.</p>
<p>Here is an example of a Neural network with one hidden layer.</p>
<p><img src="assests/img/20221114232327.png" class="img-fluid"></p>
<p><span class="math inline">\(\Theta\)</span> is the coefficients of the whole Neural network.</p>
<ul>
<li><span class="math inline">\(a^{(1)}=\hat{\textbf{x}}\)</span> is the input. <span class="math inline">\(a_0^{(1)}\)</span> is added. This is an <span class="math inline">\((n+1)\)</span>-dimension column vector.</li>
<li><span class="math inline">\(\Theta^{(1)}\)</span> is the coefficient matrix from the input layer to the hidden layer, of size <span class="math inline">\(k\times(n+1)\)</span>.</li>
<li><span class="math inline">\(z^{(2)}=\Theta^{(1)}a^{(1)}\)</span>.</li>
<li><span class="math inline">\(a^{(2)}=\sigma(z^{(2)})\)</span>, and then add <span class="math inline">\(a^{(2)}_0\)</span>. This is an <span class="math inline">\((k+1)\)</span>-dimension column vector.</li>
<li><span class="math inline">\(\Theta^{(2)}\)</span> is the coefficient matrix from the hidden layer to the output layer, of size <span class="math inline">\(r\times(k+1)\)</span>.</li>
<li><span class="math inline">\(z^{(3)}=\Theta^{(2)}a^{(2)}\)</span>.</li>
<li><span class="math inline">\(a^{(3)}=\sigma(z^{(3)})\)</span>. Since this is the output layer, <span class="math inline">\(a^{(3)}_0\)</span> won’t be added. %
These <span class="math inline">\(a^{(3)}\)</span> are <span class="math inline">\(h_{\Theta}(\textbf{x})\)</span>.</li>
</ul>
<p>The dependency is as follows:</p>
<ul>
<li><span class="math inline">\(J\)</span> depends on <span class="math inline">\(z^{(3)}\)</span> and <span class="math inline">\(a^{(3)}\)</span>.</li>
<li><span class="math inline">\(z^{(3)}\)</span> and <span class="math inline">\(a^{(3)}\)</span> depends on <span class="math inline">\(\Theta^{(2)}\)</span> and <span class="math inline">\(a^{(2)}\)</span>.</li>
<li><span class="math inline">\(z^{(2)}\)</span> and <span class="math inline">\(a^{(2)}\)</span> depends on <span class="math inline">\(\Theta^{(1)}\)</span> and <span class="math inline">\(a^{(1)}\)</span>.</li>
<li><span class="math inline">\(J\)</span> depends on <span class="math inline">\(\Theta^{(1)}\)</span>, <span class="math inline">\(\Theta^{(2)}\)</span> and <span class="math inline">\(a^{(1)}\)</span>.</li>
</ul>
<p>Each layer is represented by the following diagram:</p>
<p><img src="assests/img/20221114232354.png" class="img-fluid"></p>
<p>The diagram says:</p>
<p><span class="math display">\[
z^{(k+1)}=b^{(k)}+\Theta^{(k)}a^{(k)},\quad z^{(k+1)}_j=b^{(k)}_j+\sum \Theta^{(k)}_{jl}a^{(k)}_l,\quad a^{(k)}_j=\sigma(z^{(k)}_j).
\]</span></p>
<p>Assume <span class="math inline">\(r,j\geq1\)</span>. Then</p>
<p><span class="math display">\[
\begin{aligned}
\diffp{z^{(k+1)}_i}{a^{(k)}_r}&amp;=\diffp*{\left(b^{(k)}_i+\sum\Theta^{(k)}_{il}a^{(k)}_l\right)}{a^{(k)}_r}=\Theta_{ir}^{(k)},\\
% \diffp{z^{(k+1)}_i}{\Theta^{(k)}_{ij}}&amp;=\diffp*{\qty(a^{(k)}_0+\sum\Theta^{(k)}_{il}a^{(k)}_l)}{\Theta^{(k)}_{ij}}=a^{(k)}_j,\\
\diffp{z^{(k+1)}_i}{z^{(k)}_j}&amp;=\sum_r \diffp{z^{(k+1)}_i}{a^{k}_r}\diffp{a^{(k)}_r}{z^{(k)}_j}+\sum_{p,g}\diffp{z^{(k+1)}_i}{\Theta^{(k)}_{pq}}\diffp{\Theta^{(k)}_{pq}}{z^{(k)}_j}+\sum_r \diffp{z^{(k+1)}_i}{b^{k}_r}\diffp{b^{(k)}_r}{z^{(k)}_j}\\
&amp;=\sum_r \Theta^{(k)}_{ir}\diffp{a^{(k)}_r}{z^{(k)}_j}=\Theta^{(k)}_{ij}\diffp{a^{(k)}_j}{z^{(k)}_j}=\Theta^{(k)}_{ij}\sigma'(z^{(k)}_j),\\
\diffp{J}{z^{(k)}_j}&amp;=\sum_r \diffp{J}{z^{(k+1)}_r}\diffp{z^{(k+1)}_r}{z^{(k)}_j}=\sum_r\diffp{J}{z^{(k+1)}_r}\Theta^{(k)}_{rj}\sigma'(z^{(k)}_j).
\end{aligned}
\]</span></p>
<p>We set</p>
<ul>
<li><span class="math inline">\(\delta^k_j=\diffp{J}{z^{(k)}_j}\)</span>, <span class="math inline">\(\delta^k=\left[\delta^k_1,\delta_2^k,\ldots\right]^T\)</span>.</li>
<li><span class="math inline">\(\mathbf{z}^k=\left[z^{(k)}_1,z^{(k)}_2,\ldots\right]^T\)</span>, <span class="math inline">\(\mathbf{a}^k=\left[a^{(k)}_1,a^{(k)}_2,\ldots\right]^T\)</span>, <span class="math inline">\(\hat{\mathbf{a}}^k=\left[a^{(k)}_0,a^{(k)}_1,\ldots\right]^T\)</span>.</li>
<li><span class="math inline">\(\Theta^{k}=\left[\Theta^{(k)}_{ij}\right]\)</span>.</li>
</ul>
<p>Then we have the following formula. Note that there are ``<span class="math inline">\(z_0\)</span>’’ terms.</p>
<p><span class="math display">\[
    \delta^k=\left[(\Theta^k)^T\delta^{k+1}\right]\circ \sigma'(\mathbf{z}^k).
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
\diffp{z^{(k+1)}_r}{\Theta^{(k)}_{pq}}&amp;=\diffp*{\left(b^{(k)}_r+\sum_l\Theta^{(k)}_{rl}a^{(k)}_l\right)}{\Theta^{(k)}_{pq}}=\begin{cases}
0&amp;\text{ for }r\neq q,\\
a^{(k)}_q&amp;\text{ for }r=q,
\end{cases}\\
\diffp{J}{\Theta^{(k)}_{pq}}&amp;=\sum_{r}\diffp{J}{z^{(k+1)}_r}\diffp{z^{(k+1)}_r}{\Theta^{(k)}_{pq}}=\diffp{J}{z^{(k+1)}_p}\diffp{z^{(k+1)}_p}{\Theta^{(k)}_{pq}}=\delta^{k+1}_pa^{k}_q,\\
\diffp{J}{b^{(k)}_{j}}&amp;=\sum_{r}\diffp{J}{z^{(k+1)}_r}\diffp{z^{(k+1)}_r}{b^{(k)}_{j}}=\diffp{J}{z^{(k+1)}_j}\diffp{z^{(k+1)}_j}{b^{(k)}_{j}}=\diffp{J}{z^{(k+1)}_j}=\delta^{k+1}_j.
\end{aligned}
\]</span></p>
<p>Extend <span class="math inline">\(\hat{\Theta}=\left[b^{(k)},\Theta^{(k)}\right]\)</span>, and <span class="math inline">\(\partial^k J=\left[\diffp{J}{\hat{\Theta}^{(k)}_{ij}}\right]\)</span>. Then <span class="math display">\[
    \partial^k J=\left[\delta^{k+1}, \delta^{k+1}(\mathbf{a}^k)^T\right].
\]</span> Then the algorithm is as follows.</p>
<ol type="1">
<li>Starting from <span class="math inline">\(x\)</span>, <span class="math inline">\(y\)</span> and some random <span class="math inline">\(\Theta\)</span>.</li>
<li>Forward computation: compute <span class="math inline">\(z^{(k)}\)</span> and <span class="math inline">\(a^{(k)}\)</span>. The last <span class="math inline">\(a^{(n)}\)</span> is <span class="math inline">\(h\)</span>.</li>
<li>Compute <span class="math inline">\(\delta^n=\nabla J\circ\sigma'(z^{(n)})\)</span>. In the case of <span class="math inline">\(J=\frac12||{h-y}||^2\)</span>, <span class="math inline">\(\nabla J=(a^{(n)}-y)\)</span>, and then <span class="math inline">\(\delta^n=(a^{(n)}-y)\circ\sigma'(z^{(n)})\)</span>.</li>
<li>Backwards: <span class="math inline">\(\delta^k=\left[(\Theta^k)^T\delta^{k+1}\right]\circ \sigma'(\mathbf{z}^k)\)</span>, and <span class="math inline">\(\partial^k J=\left[\delta^{k+1}, \delta^{k+1}(\mathbf{a}^k)^T\right]\)</span> .</li>
</ol>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.1</strong></span> Consider there are 3 layers: input, hidden and output. There are <span class="math inline">\(m+1\)</span> nodes in the input layer, <span class="math inline">\(n+1\)</span> nodes in the hidden layer and <span class="math inline">\(k\)</span> in the output layer. Therefore</p>
<ul>
<li><span class="math inline">\(a^{(1)}\)</span> and <span class="math inline">\(\delta^1\)</span> are <span class="math inline">\(m\)</span>-dim column vectors.</li>
<li><span class="math inline">\(z^{(2)}\)</span>, <span class="math inline">\(a^{(2)}\)</span> and <span class="math inline">\(\delta^2\)</span> are <span class="math inline">\(n\)</span>-dim column vectors.</li>
<li><span class="math inline">\(z^{(3)}\)</span>, <span class="math inline">\(a^{(3)}\)</span> and <span class="math inline">\(\delta^3\)</span> are <span class="math inline">\(k\)</span>-dim column vectors.</li>
<li><span class="math inline">\(\hat{\Theta}^1\)</span> is <span class="math inline">\(n\times(m+1)\)</span>, <span class="math inline">\(\hat{\Theta}^2\)</span> is <span class="math inline">\(k\times(n+1)\)</span>.</li>
<li><span class="math inline">\(z^{(2)}=b^{(1)}+\Theta^{(1)}a^{(1)}=\hat{\Theta}^{(1)}\hat{a}^{(1)}\)</span>, <span class="math inline">\(z^{(3)}=b^{(2)}+\Theta^{(2)}a^{(2)}=\hat{\Theta}^{(2)}\hat{a}^{(2)}\)</span>.</li>
<li><span class="math inline">\(\delta^3=\nabla_aJ\circ\sigma'(z^{(3)})\)</span>. This is a <span class="math inline">\(k\)</span>-dim column vector.</li>
<li><span class="math inline">\(\partial^2 J=\left[\delta^3,\delta^3(a^{(2)})^T\right]\)</span>.</li>
<li><span class="math inline">\(\delta^2=\left[(\Theta^2)^T\delta^3\right]\circ \sigma'(z^{(2)})\)</span>, where <span class="math inline">\((\hat{\Theta^2})^T\delta^3=(\hat{\Theta^2})^T\delta^3\)</span> and then remove the first row.</li>
<li><span class="math inline">\(\delta^1=\begin{bmatrix}(\Theta^1)^T\delta^2\end{bmatrix}\circ \sigma'(z^{(1)})\)</span>, where <span class="math inline">\((\hat{\Theta^1})^T\delta^2=(\hat{\Theta^1})^T\delta^2\)</span> and then remove the first row.</li>
<li><span class="math inline">\(\partial^1 J=\left[\delta^2,\delta^2(a^{(1)})^T\right]\)</span>.</li>
<li>When <span class="math inline">\(J=-\frac1m\sum y\ln a+(1-y)\ln(1-a)\)</span>, <span class="math inline">\(\delta^3=\frac1m(\sum a^{(3)}-\sum y)\)</span>.</li>
</ul>
</div>
</section>
<section id="example" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="example"><span class="header-section-number">7.2</span> Example</h2>
<p>Let us take some of our old dataset as an example. This is an continuation of the horse colic dataset from Logistic regression. Note that most of the codes are directly taken from logistic regression section, since MLP is just a generalization of logistic regression.</p>
<div id="eec12b54" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>filepath <span class="op">=</span> <span class="st">"assests/datasets/horse_colic_clean.csv"</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(filepath)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.iloc[:, :<span class="dv">22</span>].to_numpy().astype(<span class="bu">float</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> (df.iloc[:, <span class="dv">22</span>]<span class="op">&lt;</span><span class="dv">2</span>).to_numpy().astype(<span class="bu">int</span>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>SEED <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.15</span>, random_state<span class="op">=</span>SEED)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> MinMaxScaler</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>mms <span class="op">=</span> MinMaxScaler()</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>mms.fit(X_train)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> mms.transform(X_train)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> mms.transform(X_test)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>The data is feed into the dataloader. Note that we change the batch size of the test dataloader to be the whole set, since I don’t want to do batch evaluation. This can be modified accordingly.</p>
<div id="16136e60" class="cell" data-execution_count="2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset, DataLoader</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MyDataset(Dataset):</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, X, y):</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.X <span class="op">=</span> torch.tensor(X, dtype<span class="op">=</span>torch.float32)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y <span class="op">=</span> torch.tensor(y, dtype<span class="op">=</span>torch.float32).view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.X.shape[<span class="dv">0</span>]</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx):</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (<span class="va">self</span>.X[idx], <span class="va">self</span>.y[idx])</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> DataLoader(MyDataset(X_train, y_train), batch_size <span class="op">=</span><span class="dv">32</span>)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>val_loader <span class="op">=</span> DataLoader(MyDataset(X_test, y_test), batch_size<span class="op">=</span>X_test.shape[<span class="dv">0</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Now we build a neural network. This is a 2-layer model, with 1 hidden layer with 10 nodes. Since we are going to use BCEWithLogitsLoss, we don’t add the final activation function here in the model, but leave it to the loss function.</p>
<div id="43e6d8dd" class="cell" data-execution_count="3">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MyModel(nn.Module):</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_inputs):</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linear1 <span class="op">=</span> nn.Linear(num_inputs, <span class="dv">20</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.act1 <span class="op">=</span> nn.ReLU()</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linear2 <span class="op">=</span> nn.Linear(<span class="dv">20</span>, <span class="dv">1</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># self.act2 = nn.Sigmoid()</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.linear1(x)</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.act1(x)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.linear2(x)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># x = self.act2(x)</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> MyModel(<span class="dv">22</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>We could use the following code to look at the structure of the model.</p>
<div id="91a30bee" class="cell" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>total <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> n, p <span class="kw">in</span> model.named_parameters():</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(n, p.shape, p.numel())</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    total <span class="op">+=</span> p.numel()</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"total params:"</span>, total)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>linear1.weight torch.Size([20, 22]) 440
linear1.bias torch.Size([20]) 20
linear2.weight torch.Size([1, 20]) 20
linear2.bias torch.Size([1]) 1
total params: 481</code></pre>
</div>
</div>
<p>Now we start to train the model and evaluate. Note that the majority part of the code is about evaluating the result. Since we are doing binary classification, our result can be computed by checking whether our model output (before the final sigmoid function) is positive or negative. This is where <code>(p&gt;0)</code> comes from.</p>
<div id="8c3ca17a" class="cell" data-output-fold="true" data-output-summary="Click to view results" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.optim <span class="im">import</span> SGD</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.nn <span class="im">import</span> BCEWithLogitsLoss</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> MyModel(<span class="dv">22</span>)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>optim <span class="op">=</span> SGD(model.parameters(), lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> BCEWithLogitsLoss()</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>n_epochs <span class="op">=</span> <span class="dv">30</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Meter:</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, total<span class="op">=</span><span class="fl">0.0</span>, count<span class="op">=</span><span class="dv">0</span>, value<span class="op">=</span><span class="fl">0.0</span>):</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.total <span class="op">=</span> total</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.count <span class="op">=</span> count</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.value <span class="op">=</span> value</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.avg <span class="op">=</span> <span class="va">self</span>.total <span class="op">/</span> <span class="va">self</span>.count <span class="cf">if</span> <span class="va">self</span>.count <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="fl">0.0</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> update(<span class="va">self</span>, value, n<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.value <span class="op">=</span> value</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.total <span class="op">+=</span> value <span class="op">*</span> n</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.count <span class="op">+=</span> n</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.avg <span class="op">=</span> <span class="va">self</span>.total <span class="op">/</span> <span class="va">self</span>.count <span class="cf">if</span> <span class="va">self</span>.count <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="fl">0.0</span></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> {<span class="st">'loss'</span>: [], <span class="st">'acc'</span>: [], <span class="st">'loss_test'</span>: [], <span class="st">'acc_test'</span>: []}</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(n_epochs):</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>    monitor_loss <span class="op">=</span> Meter()</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>    monitor_loss_test <span class="op">=</span> Meter()</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>    monitor_acc <span class="op">=</span> Meter()</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>    monitor_acc_test <span class="op">=</span> Meter()</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>    monitor_time <span class="op">=</span> Meter()</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, (X_batch, y_batch) <span class="kw">in</span> <span class="bu">enumerate</span>(train_loader):</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>        model.train()</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>        t0 <span class="op">=</span> time.perf_counter()</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>        optim.zero_grad()</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>        p <span class="op">=</span> model(X_batch)</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss_fn(p, y_batch)</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a>        optim.step()</span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a>        t1 <span class="op">=</span> time.perf_counter()</span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>            pred <span class="op">=</span> (p<span class="op">&gt;</span><span class="dv">0</span>).to(torch.<span class="bu">long</span>)</span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>            acc <span class="op">=</span> (pred <span class="op">==</span> y_batch).to(torch.<span class="bu">float</span>).mean().item()</span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a>            monitor_acc.update(acc, n<span class="op">=</span>X_batch.shape[<span class="dv">0</span>])</span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a>            monitor_loss.update(loss.item(), n<span class="op">=</span>X_batch.shape[<span class="dv">0</span>])</span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a>            monitor_time.update(t1<span class="op">-</span>t0, n<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(</span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f'epoch: </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">, batch: </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span><span class="bu">len</span>(train_loader)<span class="sc">}</span><span class="ss"> '</span></span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f'time: </span><span class="sc">{</span>monitor_time<span class="sc">.</span>value<span class="sc">: .4f}</span><span class="ss"> (</span><span class="sc">{</span>monitor_time<span class="sc">.</span>total<span class="sc">: .4f}</span><span class="ss">) '</span></span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f'loss: </span><span class="sc">{</span>monitor_loss<span class="sc">.</span>value<span class="sc">: .4f}</span><span class="ss"> (</span><span class="sc">{</span>monitor_loss<span class="sc">.</span>avg<span class="sc">: .4f}</span><span class="ss">) '</span></span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f'acc: </span><span class="sc">{</span>monitor_acc<span class="sc">.</span>value<span class="sc">: .2f}</span><span class="ss"> (</span><span class="sc">{</span>monitor_acc<span class="sc">.</span>avg<span class="sc">: .2f}</span><span class="ss">)'</span></span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true" tabindex="-1"></a>    history[<span class="st">'loss'</span>].append(monitor_loss.avg)</span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true" tabindex="-1"></a>    history[<span class="st">'acc'</span>].append(monitor_acc.avg)</span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb6-61"><a href="#cb6-61" aria-hidden="true" tabindex="-1"></a>        model.<span class="bu">eval</span>()</span>
<span id="cb6-62"><a href="#cb6-62" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> X_batch_test, y_batch_test <span class="kw">in</span> val_loader:</span>
<span id="cb6-63"><a href="#cb6-63" aria-hidden="true" tabindex="-1"></a>            p <span class="op">=</span> model(X_batch_test)</span>
<span id="cb6-64"><a href="#cb6-64" aria-hidden="true" tabindex="-1"></a>            loss_test <span class="op">=</span> loss_fn(p, y_batch_test)</span>
<span id="cb6-65"><a href="#cb6-65" aria-hidden="true" tabindex="-1"></a>            monitor_loss_test.update(loss_test.item(), n<span class="op">=</span>X_batch_test.shape[<span class="dv">0</span>])</span>
<span id="cb6-66"><a href="#cb6-66" aria-hidden="true" tabindex="-1"></a>            pred_test <span class="op">=</span> (p<span class="op">&gt;</span><span class="dv">0</span>).to(torch.<span class="bu">int</span>)</span>
<span id="cb6-67"><a href="#cb6-67" aria-hidden="true" tabindex="-1"></a>            acc_test <span class="op">=</span> ( pred_test <span class="op">==</span> y_batch_test).to(torch.<span class="bu">float</span>).mean().item()</span>
<span id="cb6-68"><a href="#cb6-68" aria-hidden="true" tabindex="-1"></a>            monitor_acc_test.update(acc_test, n<span class="op">=</span>X_batch_test.shape[<span class="dv">0</span>])</span>
<span id="cb6-69"><a href="#cb6-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-70"><a href="#cb6-70" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(</span>
<span id="cb6-71"><a href="#cb6-71" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f'test epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss"> '</span></span>
<span id="cb6-72"><a href="#cb6-72" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f'test loss: </span><span class="sc">{</span>monitor_loss_test<span class="sc">.</span>avg<span class="sc">: .4f}</span><span class="ss"> '</span></span>
<span id="cb6-73"><a href="#cb6-73" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f'test acc: </span><span class="sc">{</span>monitor_acc_test<span class="sc">.</span>avg<span class="sc">: .2f}</span><span class="ss">'</span></span>
<span id="cb6-74"><a href="#cb6-74" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-75"><a href="#cb6-75" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">'loss_test'</span>].append(monitor_loss_test.avg)</span>
<span id="cb6-76"><a href="#cb6-76" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">'acc_test'</span>].append(monitor_acc_test.avg)</span>
<span id="cb6-77"><a href="#cb6-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-78"><a href="#cb6-78" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb6-79"><a href="#cb6-79" aria-hidden="true" tabindex="-1"></a>fig.set_size_inches((<span class="dv">10</span>,<span class="dv">3</span>))</span>
<span id="cb6-80"><a href="#cb6-80" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].plot(history[<span class="st">'loss'</span>], label<span class="op">=</span><span class="st">'training_loss'</span>)</span>
<span id="cb6-81"><a href="#cb6-81" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].plot(history[<span class="st">'loss_test'</span>], label<span class="op">=</span><span class="st">'testing_loss'</span>)</span>
<span id="cb6-82"><a href="#cb6-82" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].legend()</span>
<span id="cb6-83"><a href="#cb6-83" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].plot(history[<span class="st">'acc'</span>], label<span class="op">=</span><span class="st">'training_acc'</span>)</span>
<span id="cb6-84"><a href="#cb6-84" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].plot(history[<span class="st">'acc_test'</span>], label<span class="op">=</span><span class="st">'testing_acc'</span>)</span>
<span id="cb6-85"><a href="#cb6-85" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].legend()</span>
<span id="cb6-86"><a href="#cb6-86" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].set_title(<span class="st">'Loss'</span>)<span class="op">;</span></span>
<span id="cb6-87"><a href="#cb6-87" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].set_title(<span class="st">'Accuracy'</span>)<span class="op">;</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<details><summary>Click to view results</summary>
<div class="cell-output cell-output-stdout">
<pre><code>epoch: 0, batch: 1/10 time:  0.0024 ( 0.0024) loss:  0.7130 ( 0.7130) acc:  0.53 ( 0.53)
epoch: 0, batch: 2/10 time:  0.0004 ( 0.0028) loss:  0.6545 ( 0.6837) acc:  0.75 ( 0.64)
epoch: 0, batch: 3/10 time:  0.0004 ( 0.0031) loss:  0.6738 ( 0.6804) acc:  0.72 ( 0.67)
epoch: 0, batch: 4/10 time:  0.0003 ( 0.0035) loss:  0.6839 ( 0.6813) acc:  0.69 ( 0.67)
epoch: 0, batch: 5/10 time:  0.0003 ( 0.0038) loss:  0.6855 ( 0.6821) acc:  0.66 ( 0.67)
epoch: 0, batch: 6/10 time:  0.0003 ( 0.0041) loss:  0.7146 ( 0.6876) acc:  0.56 ( 0.65)
epoch: 0, batch: 7/10 time:  0.0004 ( 0.0045) loss:  0.6453 ( 0.6815) acc:  0.75 ( 0.67)
epoch: 0, batch: 8/10 time:  0.0005 ( 0.0050) loss:  0.7178 ( 0.6860) acc:  0.47 ( 0.64)
epoch: 0, batch: 9/10 time:  0.0005 ( 0.0054) loss:  0.7476 ( 0.6929) acc:  0.44 ( 0.62)
epoch: 0, batch: 10/10 time:  0.0005 ( 0.0060) loss:  0.6796 ( 0.6919) acc:  0.58 ( 0.62)
test epoch 0 test loss:  0.6804 test acc:  0.62
epoch: 1, batch: 1/10 time:  0.0004 ( 0.0004) loss:  0.6993 ( 0.6993) acc:  0.53 ( 0.53)
epoch: 1, batch: 2/10 time:  0.0004 ( 0.0008) loss:  0.6498 ( 0.6746) acc:  0.75 ( 0.64)
epoch: 1, batch: 3/10 time:  0.0004 ( 0.0012) loss:  0.6645 ( 0.6712) acc:  0.72 ( 0.67)
epoch: 1, batch: 4/10 time:  0.0004 ( 0.0016) loss:  0.6700 ( 0.6709) acc:  0.69 ( 0.67)
epoch: 1, batch: 5/10 time:  0.0004 ( 0.0020) loss:  0.6724 ( 0.6712) acc:  0.66 ( 0.67)
epoch: 1, batch: 6/10 time:  0.0004 ( 0.0023) loss:  0.7015 ( 0.6763) acc:  0.56 ( 0.65)
epoch: 1, batch: 7/10 time:  0.0004 ( 0.0027) loss:  0.6374 ( 0.6707) acc:  0.75 ( 0.67)
epoch: 1, batch: 8/10 time:  0.0004 ( 0.0031) loss:  0.7109 ( 0.6757) acc:  0.47 ( 0.64)
epoch: 1, batch: 9/10 time:  0.0004 ( 0.0035) loss:  0.7332 ( 0.6821) acc:  0.44 ( 0.62)
epoch: 1, batch: 10/10 time:  0.0004 ( 0.0039) loss:  0.6723 ( 0.6814) acc:  0.58 ( 0.62)
test epoch 1 test loss:  0.6716 test acc:  0.62
epoch: 2, batch: 1/10 time:  0.0004 ( 0.0004) loss:  0.6894 ( 0.6894) acc:  0.53 ( 0.53)
epoch: 2, batch: 2/10 time:  0.0004 ( 0.0008) loss:  0.6430 ( 0.6662) acc:  0.75 ( 0.64)
epoch: 2, batch: 3/10 time:  0.0004 ( 0.0011) loss:  0.6555 ( 0.6626) acc:  0.72 ( 0.67)
epoch: 2, batch: 4/10 time:  0.0004 ( 0.0015) loss:  0.6573 ( 0.6613) acc:  0.69 ( 0.67)
epoch: 2, batch: 5/10 time:  0.0004 ( 0.0019) loss:  0.6609 ( 0.6612) acc:  0.66 ( 0.67)
epoch: 2, batch: 6/10 time:  0.0004 ( 0.0023) loss:  0.6906 ( 0.6661) acc:  0.56 ( 0.65)
epoch: 2, batch: 7/10 time:  0.0007 ( 0.0030) loss:  0.6289 ( 0.6608) acc:  0.75 ( 0.67)
epoch: 2, batch: 8/10 time:  0.0005 ( 0.0035) loss:  0.7063 ( 0.6665) acc:  0.47 ( 0.64)
epoch: 2, batch: 9/10 time:  0.0005 ( 0.0039) loss:  0.7232 ( 0.6728) acc:  0.44 ( 0.62)
epoch: 2, batch: 10/10 time:  0.0006 ( 0.0045) loss:  0.6659 ( 0.6723) acc:  0.58 ( 0.62)
test epoch 2 test loss:  0.6638 test acc:  0.62
epoch: 3, batch: 1/10 time:  0.0004 ( 0.0004) loss:  0.6810 ( 0.6810) acc:  0.53 ( 0.53)
epoch: 3, batch: 2/10 time:  0.0004 ( 0.0008) loss:  0.6363 ( 0.6586) acc:  0.75 ( 0.64)
epoch: 3, batch: 3/10 time:  0.0004 ( 0.0012) loss:  0.6469 ( 0.6547) acc:  0.72 ( 0.67)
epoch: 3, batch: 4/10 time:  0.0004 ( 0.0016) loss:  0.6459 ( 0.6525) acc:  0.69 ( 0.67)
epoch: 3, batch: 5/10 time:  0.0004 ( 0.0020) loss:  0.6505 ( 0.6521) acc:  0.66 ( 0.67)
epoch: 3, batch: 6/10 time:  0.0004 ( 0.0024) loss:  0.6809 ( 0.6569) acc:  0.56 ( 0.65)
epoch: 3, batch: 7/10 time:  0.0004 ( 0.0028) loss:  0.6205 ( 0.6517) acc:  0.75 ( 0.67)
epoch: 3, batch: 8/10 time:  0.0004 ( 0.0031) loss:  0.7025 ( 0.6581) acc:  0.47 ( 0.64)
epoch: 3, batch: 9/10 time:  0.0004 ( 0.0035) loss:  0.7146 ( 0.6643) acc:  0.44 ( 0.62)
epoch: 3, batch: 10/10 time:  0.0004 ( 0.0039) loss:  0.6597 ( 0.6640) acc:  0.58 ( 0.62)
test epoch 3 test loss:  0.6561 test acc:  0.62
epoch: 4, batch: 1/10 time:  0.0004 ( 0.0004) loss:  0.6728 ( 0.6728) acc:  0.53 ( 0.53)
epoch: 4, batch: 2/10 time:  0.0004 ( 0.0008) loss:  0.6297 ( 0.6513) acc:  0.75 ( 0.64)
epoch: 4, batch: 3/10 time:  0.0004 ( 0.0011) loss:  0.6387 ( 0.6471) acc:  0.72 ( 0.67)
epoch: 4, batch: 4/10 time:  0.0004 ( 0.0015) loss:  0.6350 ( 0.6440) acc:  0.69 ( 0.67)
epoch: 4, batch: 5/10 time:  0.0004 ( 0.0019) loss:  0.6402 ( 0.6433) acc:  0.66 ( 0.67)
epoch: 4, batch: 6/10 time:  0.0005 ( 0.0024) loss:  0.6716 ( 0.6480) acc:  0.56 ( 0.65)
epoch: 4, batch: 7/10 time:  0.0006 ( 0.0029) loss:  0.6119 ( 0.6428) acc:  0.75 ( 0.67)
epoch: 4, batch: 8/10 time:  0.0004 ( 0.0033) loss:  0.6987 ( 0.6498) acc:  0.47 ( 0.64)
epoch: 4, batch: 9/10 time:  0.0004 ( 0.0037) loss:  0.7059 ( 0.6561) acc:  0.44 ( 0.62)
epoch: 4, batch: 10/10 time:  0.0004 ( 0.0041) loss:  0.6528 ( 0.6558) acc:  0.58 ( 0.62)
test epoch 4 test loss:  0.6484 test acc:  0.64
epoch: 5, batch: 1/10 time:  0.0004 ( 0.0004) loss:  0.6643 ( 0.6643) acc:  0.53 ( 0.53)
epoch: 5, batch: 2/10 time:  0.0004 ( 0.0008) loss:  0.6235 ( 0.6439) acc:  0.75 ( 0.64)
epoch: 5, batch: 3/10 time:  0.0004 ( 0.0011) loss:  0.6306 ( 0.6395) acc:  0.72 ( 0.67)
epoch: 5, batch: 4/10 time:  0.0004 ( 0.0015) loss:  0.6240 ( 0.6356) acc:  0.69 ( 0.67)
epoch: 5, batch: 5/10 time:  0.0004 ( 0.0019) loss:  0.6296 ( 0.6344) acc:  0.66 ( 0.67)
epoch: 5, batch: 6/10 time:  0.0004 ( 0.0022) loss:  0.6617 ( 0.6390) acc:  0.56 ( 0.65)
epoch: 5, batch: 7/10 time:  0.0004 ( 0.0026) loss:  0.6032 ( 0.6338) acc:  0.75 ( 0.67)
epoch: 5, batch: 8/10 time:  0.0004 ( 0.0030) loss:  0.6947 ( 0.6415) acc:  0.47 ( 0.64)
epoch: 5, batch: 9/10 time:  0.0004 ( 0.0033) loss:  0.6963 ( 0.6475) acc:  0.47 ( 0.62)
epoch: 5, batch: 10/10 time:  0.0004 ( 0.0037) loss:  0.6452 ( 0.6474) acc:  0.62 ( 0.62)
test epoch 5 test loss:  0.6402 test acc:  0.64
epoch: 6, batch: 1/10 time:  0.0004 ( 0.0004) loss:  0.6549 ( 0.6549) acc:  0.53 ( 0.53)
epoch: 6, batch: 2/10 time:  0.0004 ( 0.0007) loss:  0.6179 ( 0.6364) acc:  0.78 ( 0.66)
epoch: 6, batch: 3/10 time:  0.0004 ( 0.0011) loss:  0.6225 ( 0.6318) acc:  0.69 ( 0.67)
epoch: 6, batch: 4/10 time:  0.0004 ( 0.0015) loss:  0.6124 ( 0.6269) acc:  0.69 ( 0.67)
epoch: 6, batch: 5/10 time:  0.0005 ( 0.0020) loss:  0.6187 ( 0.6253) acc:  0.66 ( 0.67)
epoch: 6, batch: 6/10 time:  0.0005 ( 0.0025) loss:  0.6511 ( 0.6296) acc:  0.56 ( 0.65)
epoch: 6, batch: 7/10 time:  0.0004 ( 0.0028) loss:  0.5940 ( 0.6245) acc:  0.75 ( 0.67)
epoch: 6, batch: 8/10 time:  0.0003 ( 0.0031) loss:  0.6900 ( 0.6327) acc:  0.47 ( 0.64)
epoch: 6, batch: 9/10 time:  0.0003 ( 0.0035) loss:  0.6855 ( 0.6386) acc:  0.50 ( 0.62)
epoch: 6, batch: 10/10 time:  0.0003 ( 0.0038) loss:  0.6371 ( 0.6384) acc:  0.67 ( 0.63)
test epoch 6 test loss:  0.6315 test acc:  0.61
epoch: 7, batch: 1/10 time:  0.0003 ( 0.0003) loss:  0.6449 ( 0.6449) acc:  0.59 ( 0.59)
epoch: 7, batch: 2/10 time:  0.0003 ( 0.0006) loss:  0.6124 ( 0.6287) acc:  0.78 ( 0.69)
epoch: 7, batch: 3/10 time:  0.0003 ( 0.0010) loss:  0.6139 ( 0.6237) acc:  0.69 ( 0.69)
epoch: 7, batch: 4/10 time:  0.0003 ( 0.0013) loss:  0.5999 ( 0.6178) acc:  0.66 ( 0.68)
epoch: 7, batch: 5/10 time:  0.0003 ( 0.0016) loss:  0.6070 ( 0.6156) acc:  0.66 ( 0.68)
epoch: 7, batch: 6/10 time:  0.0003 ( 0.0019) loss:  0.6396 ( 0.6196) acc:  0.62 ( 0.67)
epoch: 7, batch: 7/10 time:  0.0003 ( 0.0022) loss:  0.5842 ( 0.6146) acc:  0.78 ( 0.68)
epoch: 7, batch: 8/10 time:  0.0003 ( 0.0025) loss:  0.6850 ( 0.6234) acc:  0.53 ( 0.66)
epoch: 7, batch: 9/10 time:  0.0003 ( 0.0028) loss:  0.6741 ( 0.6290) acc:  0.50 ( 0.65)
epoch: 7, batch: 10/10 time:  0.0003 ( 0.0031) loss:  0.6284 ( 0.6290) acc:  0.71 ( 0.65)
test epoch 7 test loss:  0.6221 test acc:  0.66
epoch: 8, batch: 1/10 time:  0.0003 ( 0.0003) loss:  0.6344 ( 0.6344) acc:  0.62 ( 0.62)
epoch: 8, batch: 2/10 time:  0.0003 ( 0.0006) loss:  0.6066 ( 0.6205) acc:  0.72 ( 0.67)
epoch: 8, batch: 3/10 time:  0.0003 ( 0.0009) loss:  0.6045 ( 0.6152) acc:  0.69 ( 0.68)
epoch: 8, batch: 4/10 time:  0.0003 ( 0.0012) loss:  0.5863 ( 0.6080) acc:  0.62 ( 0.66)
epoch: 8, batch: 5/10 time:  0.0003 ( 0.0016) loss:  0.5947 ( 0.6053) acc:  0.69 ( 0.67)
epoch: 8, batch: 6/10 time:  0.0003 ( 0.0019) loss:  0.6273 ( 0.6090) acc:  0.66 ( 0.67)
epoch: 8, batch: 7/10 time:  0.0003 ( 0.0022) loss:  0.5738 ( 0.6040) acc:  0.78 ( 0.68)
epoch: 8, batch: 8/10 time:  0.0003 ( 0.0025) loss:  0.6802 ( 0.6135) acc:  0.53 ( 0.66)
epoch: 8, batch: 9/10 time:  0.0004 ( 0.0030) loss:  0.6623 ( 0.6189) acc:  0.53 ( 0.65)
epoch: 8, batch: 10/10 time:  0.0004 ( 0.0034) loss:  0.6194 ( 0.6190) acc:  0.75 ( 0.66)
test epoch 8 test loss:  0.6124 test acc:  0.70
epoch: 9, batch: 1/10 time:  0.0004 ( 0.0004) loss:  0.6236 ( 0.6236) acc:  0.66 ( 0.66)
epoch: 9, batch: 2/10 time:  0.0004 ( 0.0008) loss:  0.6014 ( 0.6125) acc:  0.75 ( 0.70)
epoch: 9, batch: 3/10 time:  0.0004 ( 0.0012) loss:  0.5949 ( 0.6066) acc:  0.69 ( 0.70)
epoch: 9, batch: 4/10 time:  0.0004 ( 0.0015) loss:  0.5720 ( 0.5980) acc:  0.72 ( 0.70)
epoch: 9, batch: 5/10 time:  0.0004 ( 0.0019) loss:  0.5818 ( 0.5947) acc:  0.72 ( 0.71)
epoch: 9, batch: 6/10 time:  0.0004 ( 0.0023) loss:  0.6144 ( 0.5980) acc:  0.62 ( 0.69)
epoch: 9, batch: 7/10 time:  0.0004 ( 0.0027) loss:  0.5629 ( 0.5930) acc:  0.78 ( 0.71)
epoch: 9, batch: 8/10 time:  0.0004 ( 0.0031) loss:  0.6756 ( 0.6033) acc:  0.53 ( 0.68)
epoch: 9, batch: 9/10 time:  0.0004 ( 0.0034) loss:  0.6501 ( 0.6085) acc:  0.56 ( 0.67)
epoch: 9, batch: 10/10 time:  0.0004 ( 0.0038) loss:  0.6101 ( 0.6087) acc:  0.75 ( 0.68)
test epoch 9 test loss:  0.6025 test acc:  0.73
epoch: 10, batch: 1/10 time:  0.0004 ( 0.0004) loss:  0.6130 ( 0.6130) acc:  0.66 ( 0.66)
epoch: 10, batch: 2/10 time:  0.0004 ( 0.0008) loss:  0.5961 ( 0.6046) acc:  0.75 ( 0.70)
epoch: 10, batch: 3/10 time:  0.0004 ( 0.0012) loss:  0.5851 ( 0.5981) acc:  0.69 ( 0.70)
epoch: 10, batch: 4/10 time:  0.0004 ( 0.0016) loss:  0.5572 ( 0.5879) acc:  0.75 ( 0.71)
epoch: 10, batch: 5/10 time:  0.0004 ( 0.0020) loss:  0.5689 ( 0.5841) acc:  0.72 ( 0.71)
epoch: 10, batch: 6/10 time:  0.0004 ( 0.0023) loss:  0.6012 ( 0.5869) acc:  0.66 ( 0.70)
epoch: 10, batch: 7/10 time:  0.0004 ( 0.0027) loss:  0.5517 ( 0.5819) acc:  0.75 ( 0.71)
epoch: 10, batch: 8/10 time:  0.0006 ( 0.0033) loss:  0.6716 ( 0.5931) acc:  0.56 ( 0.69)
epoch: 10, batch: 9/10 time:  0.0005 ( 0.0038) loss:  0.6380 ( 0.5981) acc:  0.66 ( 0.69)
epoch: 10, batch: 10/10 time:  0.0004 ( 0.0042) loss:  0.6011 ( 0.5983) acc:  0.75 ( 0.69)
test epoch 10 test loss:  0.5930 test acc:  0.71
epoch: 11, batch: 1/10 time:  0.0003 ( 0.0003) loss:  0.6028 ( 0.6028) acc:  0.69 ( 0.69)
epoch: 11, batch: 2/10 time:  0.0003 ( 0.0007) loss:  0.5911 ( 0.5969) acc:  0.72 ( 0.70)
epoch: 11, batch: 3/10 time:  0.0003 ( 0.0010) loss:  0.5750 ( 0.5896) acc:  0.72 ( 0.71)
epoch: 11, batch: 4/10 time:  0.0003 ( 0.0013) loss:  0.5421 ( 0.5778) acc:  0.78 ( 0.73)
epoch: 11, batch: 5/10 time:  0.0003 ( 0.0016) loss:  0.5562 ( 0.5734) acc:  0.78 ( 0.74)
epoch: 11, batch: 6/10 time:  0.0003 ( 0.0019) loss:  0.5882 ( 0.5759) acc:  0.69 ( 0.73)
epoch: 11, batch: 7/10 time:  0.0003 ( 0.0022) loss:  0.5405 ( 0.5709) acc:  0.75 ( 0.73)
epoch: 11, batch: 8/10 time:  0.0003 ( 0.0026) loss:  0.6681 ( 0.5830) acc:  0.56 ( 0.71)
epoch: 11, batch: 9/10 time:  0.0003 ( 0.0029) loss:  0.6271 ( 0.5879) acc:  0.62 ( 0.70)
epoch: 11, batch: 10/10 time:  0.0003 ( 0.0032) loss:  0.5927 ( 0.5883) acc:  0.75 ( 0.71)
test epoch 11 test loss:  0.5835 test acc:  0.71
epoch: 12, batch: 1/10 time:  0.0003 ( 0.0003) loss:  0.5935 ( 0.5935) acc:  0.69 ( 0.69)
epoch: 12, batch: 2/10 time:  0.0003 ( 0.0006) loss:  0.5856 ( 0.5895) acc:  0.72 ( 0.70)
epoch: 12, batch: 3/10 time:  0.0003 ( 0.0010) loss:  0.5647 ( 0.5812) acc:  0.75 ( 0.72)
epoch: 12, batch: 4/10 time:  0.0003 ( 0.0013) loss:  0.5272 ( 0.5677) acc:  0.81 ( 0.74)
epoch: 12, batch: 5/10 time:  0.0003 ( 0.0016) loss:  0.5441 ( 0.5630) acc:  0.75 ( 0.74)
epoch: 12, batch: 6/10 time:  0.0003 ( 0.0019) loss:  0.5757 ( 0.5651) acc:  0.69 ( 0.73)
epoch: 12, batch: 7/10 time:  0.0003 ( 0.0022) loss:  0.5294 ( 0.5600) acc:  0.72 ( 0.73)
epoch: 12, batch: 8/10 time:  0.0003 ( 0.0025) loss:  0.6655 ( 0.5732) acc:  0.56 ( 0.71)
epoch: 12, batch: 9/10 time:  0.0003 ( 0.0028) loss:  0.6172 ( 0.5781) acc:  0.66 ( 0.70)
epoch: 12, batch: 10/10 time:  0.0003 ( 0.0031) loss:  0.5848 ( 0.5786) acc:  0.75 ( 0.71)
test epoch 12 test loss:  0.5745 test acc:  0.73
epoch: 13, batch: 1/10 time:  0.0005 ( 0.0005) loss:  0.5852 ( 0.5852) acc:  0.69 ( 0.69)
epoch: 13, batch: 2/10 time:  0.0009 ( 0.0014) loss:  0.5806 ( 0.5829) acc:  0.75 ( 0.72)
epoch: 13, batch: 3/10 time:  0.0004 ( 0.0019) loss:  0.5551 ( 0.5737) acc:  0.75 ( 0.73)
epoch: 13, batch: 4/10 time:  0.0005 ( 0.0023) loss:  0.5129 ( 0.5585) acc:  0.84 ( 0.76)
epoch: 13, batch: 5/10 time:  0.0005 ( 0.0028) loss:  0.5328 ( 0.5533) acc:  0.75 ( 0.76)
epoch: 13, batch: 6/10 time:  0.0005 ( 0.0034) loss:  0.5639 ( 0.5551) acc:  0.69 ( 0.74)
epoch: 13, batch: 7/10 time:  0.0004 ( 0.0038) loss:  0.5189 ( 0.5499) acc:  0.72 ( 0.74)
epoch: 13, batch: 8/10 time:  0.0004 ( 0.0042) loss:  0.6638 ( 0.5642) acc:  0.56 ( 0.72)
epoch: 13, batch: 9/10 time:  0.0004 ( 0.0046) loss:  0.6083 ( 0.5691) acc:  0.66 ( 0.71)
epoch: 13, batch: 10/10 time:  0.0004 ( 0.0049) loss:  0.5779 ( 0.5697) acc:  0.71 ( 0.71)
test epoch 13 test loss:  0.5664 test acc:  0.75
epoch: 14, batch: 1/10 time:  0.0004 ( 0.0004) loss:  0.5780 ( 0.5780) acc:  0.69 ( 0.69)
epoch: 14, batch: 2/10 time:  0.0004 ( 0.0008) loss:  0.5768 ( 0.5774) acc:  0.75 ( 0.72)
epoch: 14, batch: 3/10 time:  0.0004 ( 0.0012) loss:  0.5465 ( 0.5671) acc:  0.75 ( 0.73)
epoch: 14, batch: 4/10 time:  0.0004 ( 0.0016) loss:  0.4995 ( 0.5502) acc:  0.84 ( 0.76)
epoch: 14, batch: 5/10 time:  0.0004 ( 0.0020) loss:  0.5227 ( 0.5447) acc:  0.72 ( 0.75)
epoch: 14, batch: 6/10 time:  0.0004 ( 0.0024) loss:  0.5530 ( 0.5461) acc:  0.69 ( 0.74)
epoch: 14, batch: 7/10 time:  0.0004 ( 0.0028) loss:  0.5092 ( 0.5408) acc:  0.72 ( 0.74)
epoch: 14, batch: 8/10 time:  0.0004 ( 0.0032) loss:  0.6627 ( 0.5560) acc:  0.53 ( 0.71)
epoch: 14, batch: 9/10 time:  0.0004 ( 0.0036) loss:  0.5999 ( 0.5609) acc:  0.69 ( 0.71)
epoch: 14, batch: 10/10 time:  0.0007 ( 0.0043) loss:  0.5719 ( 0.5618) acc:  0.67 ( 0.71)
test epoch 14 test loss:  0.5593 test acc:  0.73
epoch: 15, batch: 1/10 time:  0.0004 ( 0.0004) loss:  0.5719 ( 0.5719) acc:  0.72 ( 0.72)
epoch: 15, batch: 2/10 time:  0.0004 ( 0.0008) loss:  0.5739 ( 0.5729) acc:  0.75 ( 0.73)
epoch: 15, batch: 3/10 time:  0.0004 ( 0.0012) loss:  0.5387 ( 0.5615) acc:  0.78 ( 0.75)
epoch: 15, batch: 4/10 time:  0.0004 ( 0.0016) loss:  0.4870 ( 0.5429) acc:  0.84 ( 0.77)
epoch: 15, batch: 5/10 time:  0.0004 ( 0.0020) loss:  0.5136 ( 0.5370) acc:  0.75 ( 0.77)
epoch: 15, batch: 6/10 time:  0.0004 ( 0.0024) loss:  0.5432 ( 0.5380) acc:  0.69 ( 0.76)
epoch: 15, batch: 7/10 time:  0.0004 ( 0.0028) loss:  0.5004 ( 0.5327) acc:  0.72 ( 0.75)
epoch: 15, batch: 8/10 time:  0.0004 ( 0.0032) loss:  0.6617 ( 0.5488) acc:  0.53 ( 0.72)
epoch: 15, batch: 9/10 time:  0.0004 ( 0.0036) loss:  0.5925 ( 0.5537) acc:  0.69 ( 0.72)
epoch: 15, batch: 10/10 time:  0.0004 ( 0.0039) loss:  0.5670 ( 0.5547) acc:  0.67 ( 0.71)
test epoch 15 test loss:  0.5531 test acc:  0.75
epoch: 16, batch: 1/10 time:  0.0004 ( 0.0004) loss:  0.5666 ( 0.5666) acc:  0.72 ( 0.72)
epoch: 16, batch: 2/10 time:  0.0004 ( 0.0008) loss:  0.5715 ( 0.5691) acc:  0.75 ( 0.73)
epoch: 16, batch: 3/10 time:  0.0004 ( 0.0012) loss:  0.5316 ( 0.5566) acc:  0.78 ( 0.75)
epoch: 16, batch: 4/10 time:  0.0004 ( 0.0016) loss:  0.4755 ( 0.5363) acc:  0.84 ( 0.77)
epoch: 16, batch: 5/10 time:  0.0004 ( 0.0020) loss:  0.5057 ( 0.5302) acc:  0.75 ( 0.77)
epoch: 16, batch: 6/10 time:  0.0004 ( 0.0024) loss:  0.5343 ( 0.5309) acc:  0.72 ( 0.76)
epoch: 16, batch: 7/10 time:  0.0004 ( 0.0028) loss:  0.4922 ( 0.5254) acc:  0.75 ( 0.76)
epoch: 16, batch: 8/10 time:  0.0005 ( 0.0033) loss:  0.6617 ( 0.5424) acc:  0.53 ( 0.73)
epoch: 16, batch: 9/10 time:  0.0004 ( 0.0037) loss:  0.5868 ( 0.5473) acc:  0.69 ( 0.73)
epoch: 16, batch: 10/10 time:  0.0003 ( 0.0040) loss:  0.5626 ( 0.5485) acc:  0.67 ( 0.72)
test epoch 16 test loss:  0.5476 test acc:  0.77
epoch: 17, batch: 1/10 time:  0.0003 ( 0.0003) loss:  0.5623 ( 0.5623) acc:  0.72 ( 0.72)
epoch: 17, batch: 2/10 time:  0.0003 ( 0.0007) loss:  0.5697 ( 0.5660) acc:  0.75 ( 0.73)
epoch: 17, batch: 3/10 time:  0.0003 ( 0.0010) loss:  0.5250 ( 0.5523) acc:  0.78 ( 0.75)
epoch: 17, batch: 4/10 time:  0.0003 ( 0.0013) loss:  0.4650 ( 0.5305) acc:  0.84 ( 0.77)
epoch: 17, batch: 5/10 time:  0.0003 ( 0.0016) loss:  0.4990 ( 0.5242) acc:  0.75 ( 0.77)
epoch: 17, batch: 6/10 time:  0.0003 ( 0.0019) loss:  0.5265 ( 0.5246) acc:  0.72 ( 0.76)
epoch: 17, batch: 7/10 time:  0.0003 ( 0.0023) loss:  0.4848 ( 0.5189) acc:  0.75 ( 0.76)
epoch: 17, batch: 8/10 time:  0.0003 ( 0.0026) loss:  0.6621 ( 0.5368) acc:  0.53 ( 0.73)
epoch: 17, batch: 9/10 time:  0.0003 ( 0.0029) loss:  0.5821 ( 0.5418) acc:  0.69 ( 0.73)
epoch: 17, batch: 10/10 time:  0.0003 ( 0.0032) loss:  0.5588 ( 0.5431) acc:  0.67 ( 0.72)
test epoch 17 test loss:  0.5430 test acc:  0.79
epoch: 18, batch: 1/10 time:  0.0003 ( 0.0003) loss:  0.5586 ( 0.5586) acc:  0.75 ( 0.75)
epoch: 18, batch: 2/10 time:  0.0003 ( 0.0006) loss:  0.5688 ( 0.5637) acc:  0.75 ( 0.75)
epoch: 18, batch: 3/10 time:  0.0003 ( 0.0010) loss:  0.5194 ( 0.5490) acc:  0.78 ( 0.76)
epoch: 18, batch: 4/10 time:  0.0003 ( 0.0013) loss:  0.4556 ( 0.5256) acc:  0.84 ( 0.78)
epoch: 18, batch: 5/10 time:  0.0003 ( 0.0016) loss:  0.4931 ( 0.5191) acc:  0.78 ( 0.78)
epoch: 18, batch: 6/10 time:  0.0003 ( 0.0019) loss:  0.5193 ( 0.5191) acc:  0.72 ( 0.77)
epoch: 18, batch: 7/10 time:  0.0003 ( 0.0022) loss:  0.4780 ( 0.5133) acc:  0.75 ( 0.77)
epoch: 18, batch: 8/10 time:  0.0003 ( 0.0025) loss:  0.6625 ( 0.5319) acc:  0.53 ( 0.74)
epoch: 18, batch: 9/10 time:  0.0003 ( 0.0028) loss:  0.5781 ( 0.5371) acc:  0.72 ( 0.74)
epoch: 18, batch: 10/10 time:  0.0003 ( 0.0032) loss:  0.5556 ( 0.5385) acc:  0.67 ( 0.73)
test epoch 18 test loss:  0.5390 test acc:  0.79
epoch: 19, batch: 1/10 time:  0.0006 ( 0.0006) loss:  0.5556 ( 0.5556) acc:  0.75 ( 0.75)
epoch: 19, batch: 2/10 time:  0.0005 ( 0.0010) loss:  0.5676 ( 0.5616) acc:  0.75 ( 0.75)
epoch: 19, batch: 3/10 time:  0.0004 ( 0.0014) loss:  0.5140 ( 0.5457) acc:  0.78 ( 0.76)
epoch: 19, batch: 4/10 time:  0.0003 ( 0.0018) loss:  0.4470 ( 0.5210) acc:  0.84 ( 0.78)
epoch: 19, batch: 5/10 time:  0.0003 ( 0.0021) loss:  0.4881 ( 0.5144) acc:  0.78 ( 0.78)
epoch: 19, batch: 6/10 time:  0.0003 ( 0.0024) loss:  0.5131 ( 0.5142) acc:  0.72 ( 0.77)
epoch: 19, batch: 7/10 time:  0.0003 ( 0.0027) loss:  0.4716 ( 0.5081) acc:  0.75 ( 0.77)
epoch: 19, batch: 8/10 time:  0.0003 ( 0.0030) loss:  0.6633 ( 0.5275) acc:  0.53 ( 0.74)
epoch: 19, batch: 9/10 time:  0.0003 ( 0.0033) loss:  0.5748 ( 0.5328) acc:  0.72 ( 0.74)
epoch: 19, batch: 10/10 time:  0.0003 ( 0.0037) loss:  0.5528 ( 0.5343) acc:  0.71 ( 0.73)
test epoch 19 test loss:  0.5359 test acc:  0.79
epoch: 20, batch: 1/10 time:  0.0003 ( 0.0003) loss:  0.5529 ( 0.5529) acc:  0.75 ( 0.75)
epoch: 20, batch: 2/10 time:  0.0003 ( 0.0006) loss:  0.5670 ( 0.5600) acc:  0.75 ( 0.75)
epoch: 20, batch: 3/10 time:  0.0003 ( 0.0009) loss:  0.5091 ( 0.5430) acc:  0.78 ( 0.76)
epoch: 20, batch: 4/10 time:  0.0003 ( 0.0013) loss:  0.4395 ( 0.5171) acc:  0.84 ( 0.78)
epoch: 20, batch: 5/10 time:  0.0003 ( 0.0016) loss:  0.4836 ( 0.5104) acc:  0.78 ( 0.78)
epoch: 20, batch: 6/10 time:  0.0003 ( 0.0019) loss:  0.5074 ( 0.5099) acc:  0.72 ( 0.77)
epoch: 20, batch: 7/10 time:  0.0003 ( 0.0022) loss:  0.4658 ( 0.5036) acc:  0.75 ( 0.77)
epoch: 20, batch: 8/10 time:  0.0003 ( 0.0025) loss:  0.6641 ( 0.5237) acc:  0.53 ( 0.74)
epoch: 20, batch: 9/10 time:  0.0003 ( 0.0028) loss:  0.5724 ( 0.5291) acc:  0.72 ( 0.74)
epoch: 20, batch: 10/10 time:  0.0003 ( 0.0031) loss:  0.5500 ( 0.5307) acc:  0.71 ( 0.73)
test epoch 20 test loss:  0.5331 test acc:  0.79
epoch: 21, batch: 1/10 time:  0.0003 ( 0.0003) loss:  0.5507 ( 0.5507) acc:  0.75 ( 0.75)
epoch: 21, batch: 2/10 time:  0.0003 ( 0.0006) loss:  0.5664 ( 0.5586) acc:  0.75 ( 0.75)
epoch: 21, batch: 3/10 time:  0.0003 ( 0.0009) loss:  0.5043 ( 0.5405) acc:  0.78 ( 0.76)
epoch: 21, batch: 4/10 time:  0.0003 ( 0.0012) loss:  0.4327 ( 0.5135) acc:  0.84 ( 0.78)
epoch: 21, batch: 5/10 time:  0.0005 ( 0.0017) loss:  0.4798 ( 0.5068) acc:  0.78 ( 0.78)
epoch: 21, batch: 6/10 time:  0.0006 ( 0.0023) loss:  0.5024 ( 0.5060) acc:  0.72 ( 0.77)
epoch: 21, batch: 7/10 time:  0.0004 ( 0.0027) loss:  0.4603 ( 0.4995) acc:  0.75 ( 0.77)
epoch: 21, batch: 8/10 time:  0.0004 ( 0.0031) loss:  0.6651 ( 0.5202) acc:  0.53 ( 0.74)
epoch: 21, batch: 9/10 time:  0.0004 ( 0.0035) loss:  0.5703 ( 0.5258) acc:  0.72 ( 0.74)
epoch: 21, batch: 10/10 time:  0.0004 ( 0.0039) loss:  0.5475 ( 0.5274) acc:  0.71 ( 0.73)
test epoch 21 test loss:  0.5309 test acc:  0.79
epoch: 22, batch: 1/10 time:  0.0004 ( 0.0004) loss:  0.5489 ( 0.5489) acc:  0.75 ( 0.75)
epoch: 22, batch: 2/10 time:  0.0004 ( 0.0008) loss:  0.5663 ( 0.5576) acc:  0.75 ( 0.75)
epoch: 22, batch: 3/10 time:  0.0004 ( 0.0012) loss:  0.5004 ( 0.5385) acc:  0.78 ( 0.76)
epoch: 22, batch: 4/10 time:  0.0004 ( 0.0016) loss:  0.4265 ( 0.5105) acc:  0.84 ( 0.78)
epoch: 22, batch: 5/10 time:  0.0004 ( 0.0019) loss:  0.4766 ( 0.5037) acc:  0.78 ( 0.78)
epoch: 22, batch: 6/10 time:  0.0004 ( 0.0023) loss:  0.4980 ( 0.5028) acc:  0.72 ( 0.77)
epoch: 22, batch: 7/10 time:  0.0004 ( 0.0027) loss:  0.4553 ( 0.4960) acc:  0.78 ( 0.77)
epoch: 22, batch: 8/10 time:  0.0004 ( 0.0031) loss:  0.6661 ( 0.5173) acc:  0.53 ( 0.74)
epoch: 22, batch: 9/10 time:  0.0004 ( 0.0035) loss:  0.5688 ( 0.5230) acc:  0.72 ( 0.74)
epoch: 22, batch: 10/10 time:  0.0004 ( 0.0039) loss:  0.5450 ( 0.5247) acc:  0.71 ( 0.74)
test epoch 22 test loss:  0.5290 test acc:  0.79
epoch: 23, batch: 1/10 time:  0.0004 ( 0.0004) loss:  0.5474 ( 0.5474) acc:  0.75 ( 0.75)
epoch: 23, batch: 2/10 time:  0.0005 ( 0.0009) loss:  0.5661 ( 0.5568) acc:  0.75 ( 0.75)
epoch: 23, batch: 3/10 time:  0.0004 ( 0.0013) loss:  0.4966 ( 0.5367) acc:  0.78 ( 0.76)
epoch: 23, batch: 4/10 time:  0.0004 ( 0.0017) loss:  0.4210 ( 0.5078) acc:  0.84 ( 0.78)
epoch: 23, batch: 5/10 time:  0.0004 ( 0.0022) loss:  0.4738 ( 0.5010) acc:  0.78 ( 0.78)
epoch: 23, batch: 6/10 time:  0.0004 ( 0.0025) loss:  0.4936 ( 0.4997) acc:  0.72 ( 0.77)
epoch: 23, batch: 7/10 time:  0.0004 ( 0.0029) loss:  0.4510 ( 0.4928) acc:  0.75 ( 0.77)
epoch: 23, batch: 8/10 time:  0.0004 ( 0.0033) loss:  0.6670 ( 0.5145) acc:  0.53 ( 0.74)
epoch: 23, batch: 9/10 time:  0.0004 ( 0.0037) loss:  0.5677 ( 0.5205) acc:  0.72 ( 0.74)
epoch: 23, batch: 10/10 time:  0.0004 ( 0.0041) loss:  0.5425 ( 0.5221) acc:  0.71 ( 0.73)
test epoch 23 test loss:  0.5275 test acc:  0.79
epoch: 24, batch: 1/10 time:  0.0004 ( 0.0004) loss:  0.5462 ( 0.5462) acc:  0.75 ( 0.75)
epoch: 24, batch: 2/10 time:  0.0004 ( 0.0008) loss:  0.5660 ( 0.5561) acc:  0.75 ( 0.75)
epoch: 24, batch: 3/10 time:  0.0004 ( 0.0012) loss:  0.4931 ( 0.5351) acc:  0.78 ( 0.76)
epoch: 24, batch: 4/10 time:  0.0004 ( 0.0016) loss:  0.4158 ( 0.5053) acc:  0.84 ( 0.78)
epoch: 24, batch: 5/10 time:  0.0004 ( 0.0019) loss:  0.4713 ( 0.4985) acc:  0.78 ( 0.78)
epoch: 24, batch: 6/10 time:  0.0004 ( 0.0023) loss:  0.4898 ( 0.4970) acc:  0.72 ( 0.77)
epoch: 24, batch: 7/10 time:  0.0004 ( 0.0027) loss:  0.4467 ( 0.4898) acc:  0.75 ( 0.77)
epoch: 24, batch: 8/10 time:  0.0004 ( 0.0031) loss:  0.6678 ( 0.5121) acc:  0.53 ( 0.74)
epoch: 24, batch: 9/10 time:  0.0004 ( 0.0035) loss:  0.5671 ( 0.5182) acc:  0.72 ( 0.74)
epoch: 24, batch: 10/10 time:  0.0004 ( 0.0039) loss:  0.5400 ( 0.5199) acc:  0.71 ( 0.73)
test epoch 24 test loss:  0.5263 test acc:  0.80
epoch: 25, batch: 1/10 time:  0.0004 ( 0.0004) loss:  0.5452 ( 0.5452) acc:  0.75 ( 0.75)
epoch: 25, batch: 2/10 time:  0.0008 ( 0.0012) loss:  0.5661 ( 0.5557) acc:  0.75 ( 0.75)
epoch: 25, batch: 3/10 time:  0.0006 ( 0.0019) loss:  0.4898 ( 0.5337) acc:  0.78 ( 0.76)
epoch: 25, batch: 4/10 time:  0.0004 ( 0.0022) loss:  0.4112 ( 0.5031) acc:  0.84 ( 0.78)
epoch: 25, batch: 5/10 time:  0.0004 ( 0.0026) loss:  0.4691 ( 0.4963) acc:  0.78 ( 0.78)
epoch: 25, batch: 6/10 time:  0.0004 ( 0.0030) loss:  0.4864 ( 0.4946) acc:  0.72 ( 0.77)
epoch: 25, batch: 7/10 time:  0.0004 ( 0.0034) loss:  0.4427 ( 0.4872) acc:  0.78 ( 0.77)
epoch: 25, batch: 8/10 time:  0.0004 ( 0.0038) loss:  0.6684 ( 0.5099) acc:  0.53 ( 0.74)
epoch: 25, batch: 9/10 time:  0.0004 ( 0.0041) loss:  0.5664 ( 0.5161) acc:  0.72 ( 0.74)
epoch: 25, batch: 10/10 time:  0.0004 ( 0.0045) loss:  0.5376 ( 0.5178) acc:  0.71 ( 0.74)
test epoch 25 test loss:  0.5255 test acc:  0.79
epoch: 26, batch: 1/10 time:  0.0004 ( 0.0004) loss:  0.5442 ( 0.5442) acc:  0.75 ( 0.75)
epoch: 26, batch: 2/10 time:  0.0004 ( 0.0008) loss:  0.5667 ( 0.5554) acc:  0.75 ( 0.75)
epoch: 26, batch: 3/10 time:  0.0004 ( 0.0011) loss:  0.4870 ( 0.5326) acc:  0.78 ( 0.76)
epoch: 26, batch: 4/10 time:  0.0004 ( 0.0015) loss:  0.4069 ( 0.5012) acc:  0.84 ( 0.78)
epoch: 26, batch: 5/10 time:  0.0004 ( 0.0019) loss:  0.4672 ( 0.4944) acc:  0.78 ( 0.78)
epoch: 26, batch: 6/10 time:  0.0004 ( 0.0022) loss:  0.4832 ( 0.4925) acc:  0.72 ( 0.77)
epoch: 26, batch: 7/10 time:  0.0004 ( 0.0026) loss:  0.4391 ( 0.4849) acc:  0.78 ( 0.77)
epoch: 26, batch: 8/10 time:  0.0004 ( 0.0030) loss:  0.6689 ( 0.5079) acc:  0.53 ( 0.74)
epoch: 26, batch: 9/10 time:  0.0004 ( 0.0033) loss:  0.5662 ( 0.5144) acc:  0.72 ( 0.74)
epoch: 26, batch: 10/10 time:  0.0004 ( 0.0037) loss:  0.5353 ( 0.5160) acc:  0.71 ( 0.74)
test epoch 26 test loss:  0.5248 test acc:  0.77
epoch: 27, batch: 1/10 time:  0.0005 ( 0.0005) loss:  0.5433 ( 0.5433) acc:  0.75 ( 0.75)
epoch: 27, batch: 2/10 time:  0.0005 ( 0.0010) loss:  0.5671 ( 0.5552) acc:  0.75 ( 0.75)
epoch: 27, batch: 3/10 time:  0.0004 ( 0.0014) loss:  0.4843 ( 0.5316) acc:  0.78 ( 0.76)
epoch: 27, batch: 4/10 time:  0.0004 ( 0.0018) loss:  0.4030 ( 0.4994) acc:  0.84 ( 0.78)
epoch: 27, batch: 5/10 time:  0.0004 ( 0.0021) loss:  0.4654 ( 0.4926) acc:  0.78 ( 0.78)
epoch: 27, batch: 6/10 time:  0.0004 ( 0.0025) loss:  0.4801 ( 0.4906) acc:  0.72 ( 0.77)
epoch: 27, batch: 7/10 time:  0.0004 ( 0.0029) loss:  0.4358 ( 0.4827) acc:  0.78 ( 0.77)
epoch: 27, batch: 8/10 time:  0.0004 ( 0.0033) loss:  0.6692 ( 0.5060) acc:  0.53 ( 0.74)
epoch: 27, batch: 9/10 time:  0.0004 ( 0.0037) loss:  0.5662 ( 0.5127) acc:  0.72 ( 0.74)
epoch: 27, batch: 10/10 time:  0.0004 ( 0.0041) loss:  0.5331 ( 0.5143) acc:  0.71 ( 0.74)
test epoch 27 test loss:  0.5242 test acc:  0.77
epoch: 28, batch: 1/10 time:  0.0004 ( 0.0004) loss:  0.5426 ( 0.5426) acc:  0.75 ( 0.75)
epoch: 28, batch: 2/10 time:  0.0004 ( 0.0008) loss:  0.5671 ( 0.5549) acc:  0.75 ( 0.75)
epoch: 28, batch: 3/10 time:  0.0004 ( 0.0012) loss:  0.4817 ( 0.5305) acc:  0.78 ( 0.76)
epoch: 28, batch: 4/10 time:  0.0004 ( 0.0015) loss:  0.3994 ( 0.4977) acc:  0.84 ( 0.78)
epoch: 28, batch: 5/10 time:  0.0004 ( 0.0019) loss:  0.4638 ( 0.4909) acc:  0.78 ( 0.78)
epoch: 28, batch: 6/10 time:  0.0004 ( 0.0023) loss:  0.4773 ( 0.4887) acc:  0.72 ( 0.77)
epoch: 28, batch: 7/10 time:  0.0004 ( 0.0027) loss:  0.4326 ( 0.4806) acc:  0.78 ( 0.77)
epoch: 28, batch: 8/10 time:  0.0005 ( 0.0032) loss:  0.6695 ( 0.5043) acc:  0.56 ( 0.75)
epoch: 28, batch: 9/10 time:  0.0004 ( 0.0035) loss:  0.5660 ( 0.5111) acc:  0.72 ( 0.74)
epoch: 28, batch: 10/10 time:  0.0004 ( 0.0039) loss:  0.5310 ( 0.5126) acc:  0.71 ( 0.74)
test epoch 28 test loss:  0.5238 test acc:  0.77
epoch: 29, batch: 1/10 time:  0.0005 ( 0.0005) loss:  0.5418 ( 0.5418) acc:  0.75 ( 0.75)
epoch: 29, batch: 2/10 time:  0.0006 ( 0.0010) loss:  0.5675 ( 0.5546) acc:  0.75 ( 0.75)
epoch: 29, batch: 3/10 time:  0.0004 ( 0.0014) loss:  0.4799 ( 0.5297) acc:  0.78 ( 0.76)
epoch: 29, batch: 4/10 time:  0.0004 ( 0.0018) loss:  0.3958 ( 0.4963) acc:  0.84 ( 0.78)
epoch: 29, batch: 5/10 time:  0.0004 ( 0.0022) loss:  0.4624 ( 0.4895) acc:  0.78 ( 0.78)
epoch: 29, batch: 6/10 time:  0.0004 ( 0.0025) loss:  0.4746 ( 0.4870) acc:  0.72 ( 0.77)
epoch: 29, batch: 7/10 time:  0.0004 ( 0.0029) loss:  0.4297 ( 0.4788) acc:  0.78 ( 0.77)
epoch: 29, batch: 8/10 time:  0.0004 ( 0.0033) loss:  0.6694 ( 0.5026) acc:  0.56 ( 0.75)
epoch: 29, batch: 9/10 time:  0.0004 ( 0.0037) loss:  0.5659 ( 0.5097) acc:  0.72 ( 0.74)
epoch: 29, batch: 10/10 time:  0.0004 ( 0.0041) loss:  0.5290 ( 0.5112) acc:  0.71 ( 0.74)
test epoch 29 test loss:  0.5236 test acc:  0.77</code></pre>
</div>
</details>
<details><summary>Click to view results</summary>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="intro_files/figure-html/cell-6-output-2.png" width="814" height="283" class="figure-img"></p>
</figure>
</div>
</div>
</details>
</div>
<p>As you may see, to build a netural network model it requires many testing. There are many established models. When you build your own architecture, you may start from there and modify it to fit your data.</p>
</section>
<section id="exercises-and-projects" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="exercises-and-projects"><span class="header-section-number">7.3</span> Exercises and Projects</h2>
<div id="exr-" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 7.1</strong></span> Please hand write a report about the details of back propagation.</p>
</div>
<div id="exr-" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 7.2</strong></span> CHOOSE ONE: Please use netural network to one of the following datasets. - the <code>iris</code> dataset. - the dating dataset. - the <code>titanic</code> dataset.</p>
<p>Please in addition answer the following questions.</p>
<ol type="1">
<li>What is your accuracy score?</li>
<li>How many epochs do you use?</li>
<li>What is the batch size do you use?</li>
<li>Plot the learning curve (loss vs epochs, accuracy vs epochs).</li>
<li>Analyze the bias / variance status.</li>
</ol>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../contents/6/intro.html" class="pagination-link" aria-label="Logistic regression">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Logistic regression</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../contents/app/setup.html" class="pagination-link" aria-label="Python IDE Setup">
        <span class="nav-page-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Python IDE Setup</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>