{
  "hash": "a2e2341f907f1833b1cea87adb2b4df7",
  "result": {
    "engine": "jupyter",
    "markdown": "# Introduction\n\nIn this Chapter we will discuss\n\n- What is Machine Learning?\n- What do typical Machine Learning problems look like?\n- What is the basic structure of Machine Learning models?\n- What is the basic work flow to use Machine Learning to solve problems? \n- Some supplementary materials, such as Linear Algebra and Python.\n\n\n\n\n\n\n## What is Machine Learning?\n\nMachine Learning is the science (and art) of programming computers so they can *learn from data* @Ger2019.\n\nHere is a slightly more general definition:\n\n> [Machine Learning is the] field of study that gives computers the ability to learn without being explicitly programmed.\n> \n>                                                        -- Arthur Samuel, 1959\n\n\n\n\nThis \"<mark>without being explicitly programmed to do so</mark>\" is the essential difference between Machine Learning and usual computing tasks. The usual way to make a computer do useful work is to have a human programmer write down rules --- a computer program --- to be followed to turn input data into appropriate answers. Machine Learning turns this around: the machine looks at the input data and the expected task outcome, and figures out what the rules should be. A Machine Learning system is *trained* rather than explicitly programmed. Itâ€™s presented with many examples relevant to a task, and it finds statistical structure in these examples that eventually allows the system to come up with rules\nfor automating the task @Cho2021.\n\n## Types of Machine Learning Systems\nThere are many different types of Machine Learning systems that it is useful to classify them in braod categories, based on different criteria. These criteria are not exclusive, and you can combine them in any way you like. \n\nThe most popular criterion for Machine Learning classification is the amount and type of supervision they get during training. In this case there are four major types.\n\n**Supervised Learning**\n    The training set you feed to the algorithm includes the desired solutions. The machines learn from the data to alter the model to get the desired output. The main task for Supervised Learning is classification and regression.\n\n**Unsupervised Learning**\n    In Unsupervised Learning, the data provided doesn't have class information or desired solutions. We just want to dig some information directly from those data themselves. Usually Unsupervised Learning is used for clustering and dimension reduction.\n\n**Reinforcement Learning**\n    In Reinforcement Learning, there is a reward system to measure how well the machine performs the task, and the machine is learning to find the strategy to maximize the rewards. Typical examples here include gaming AI and walking robots.\n\n**Semisupervised Learning**\n    This is actually a combination of Supervised Learning and Unsupervised Learning, that it is usually used to deal with data that are half labelled. \n\n\n### Tasks for Supervised Learning\n\nAs mentioned above, for Supervised Learning, there are two typical types of tasks:\n\n\n**Classification**\n    It is the task of predicting a discrete class labels. A typical classification problem is to see an handwritten digit image and recognize it.\n\n**Regression**\n    It is the task of predicting a continuous quantity. A typical regression problem is to predict the house price based on various features of the house.\n\n \nThere are a lot of other tasks that are not directly covered by these two, but these two are the most classical Supervised Learning tasks.\n\n:::{.callout-note}\nIn this course we will mainly focus on **Supervised Classification problems**.\n:::\n\n### Classification based on complexity\nAlong with the popularity boost of deep neural network, there comes another classificaiton: shallow learning vs. deep learning. Basically all but deep neural network belongs to shallow learning. Although deep learning can do a lot of fancy stuffs, shallow learning is still very good in many cases. When the performance of a shallow learning model is good enough comparing to that of a deep learning model, people tend to use the shallow learning since it is usually faster, easier to understand and easier to modify.\n\n\n\n## Basic setting for Machine learning problems\n\n\n::: {.callout-note}\nWe by default assume that we are dealing with a **Supervised** **Classification** problem.\n:::\n\n\n### Input and output data structure\nSince we are dealing with Supervised Classification problems, the desired solutions are given. These desired solutions in Classification problems are also called *labels*. The properties that the data are used to describe are called *features*. Both features and labels are usually organized as row vectors. \n\n\n:::{#exm-} \nThe example is extracted from @Har2012. There are some sample data shown in the following table. We would like to use these information to classify bird species.\n\n::: {#tbl-table .cell tbl-cap='Bird species classification based on four features' execution_count=1}\n\n::: {.cell-output .cell-output-display execution_count=1}\n```{=html}\n<style type=\"text/css\">\n#T_dbd14 th {\n  text-align: right;\n}\n#T_dbd14_row0_col0, #T_dbd14_row0_col1, #T_dbd14_row0_col2, #T_dbd14_row0_col3, #T_dbd14_row0_col4, #T_dbd14_row1_col0, #T_dbd14_row1_col1, #T_dbd14_row1_col2, #T_dbd14_row1_col3, #T_dbd14_row1_col4, #T_dbd14_row2_col0, #T_dbd14_row2_col1, #T_dbd14_row2_col2, #T_dbd14_row2_col3, #T_dbd14_row2_col4, #T_dbd14_row3_col0, #T_dbd14_row3_col1, #T_dbd14_row3_col2, #T_dbd14_row3_col3, #T_dbd14_row3_col4, #T_dbd14_row4_col0, #T_dbd14_row4_col1, #T_dbd14_row4_col2, #T_dbd14_row4_col3, #T_dbd14_row4_col4, #T_dbd14_row5_col0, #T_dbd14_row5_col1, #T_dbd14_row5_col2, #T_dbd14_row5_col3, #T_dbd14_row5_col4 {\n  text-align: right;\n}\n</style>\n<table id=\"T_dbd14\">\n  <thead>\n    <tr>\n      <th id=\"T_dbd14_level0_col0\" class=\"col_heading level0 col0\" >Weight (g)</th>\n      <th id=\"T_dbd14_level0_col1\" class=\"col_heading level0 col1\" >Wingspan (cm)</th>\n      <th id=\"T_dbd14_level0_col2\" class=\"col_heading level0 col2\" >Webbed feet?</th>\n      <th id=\"T_dbd14_level0_col3\" class=\"col_heading level0 col3\" >Back color</th>\n      <th id=\"T_dbd14_level0_col4\" class=\"col_heading level0 col4\" >Species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td id=\"T_dbd14_row0_col0\" class=\"data row0 col0\" >1000.100000</td>\n      <td id=\"T_dbd14_row0_col1\" class=\"data row0 col1\" >125.000000</td>\n      <td id=\"T_dbd14_row0_col2\" class=\"data row0 col2\" >No</td>\n      <td id=\"T_dbd14_row0_col3\" class=\"data row0 col3\" >Brown</td>\n      <td id=\"T_dbd14_row0_col4\" class=\"data row0 col4\" >Buteo jamaicensis</td>\n    </tr>\n    <tr>\n      <td id=\"T_dbd14_row1_col0\" class=\"data row1 col0\" >3000.700000</td>\n      <td id=\"T_dbd14_row1_col1\" class=\"data row1 col1\" >200.000000</td>\n      <td id=\"T_dbd14_row1_col2\" class=\"data row1 col2\" >No</td>\n      <td id=\"T_dbd14_row1_col3\" class=\"data row1 col3\" >Gray</td>\n      <td id=\"T_dbd14_row1_col4\" class=\"data row1 col4\" >Sagittarius serpentarius</td>\n    </tr>\n    <tr>\n      <td id=\"T_dbd14_row2_col0\" class=\"data row2 col0\" >3300.000000</td>\n      <td id=\"T_dbd14_row2_col1\" class=\"data row2 col1\" >220.300000</td>\n      <td id=\"T_dbd14_row2_col2\" class=\"data row2 col2\" >No</td>\n      <td id=\"T_dbd14_row2_col3\" class=\"data row2 col3\" >Gray</td>\n      <td id=\"T_dbd14_row2_col4\" class=\"data row2 col4\" >Sagittarius serpentarius</td>\n    </tr>\n    <tr>\n      <td id=\"T_dbd14_row3_col0\" class=\"data row3 col0\" >4100.000000</td>\n      <td id=\"T_dbd14_row3_col1\" class=\"data row3 col1\" >136.000000</td>\n      <td id=\"T_dbd14_row3_col2\" class=\"data row3 col2\" >Yes</td>\n      <td id=\"T_dbd14_row3_col3\" class=\"data row3 col3\" >Black</td>\n      <td id=\"T_dbd14_row3_col4\" class=\"data row3 col4\" >Gavia immer</td>\n    </tr>\n    <tr>\n      <td id=\"T_dbd14_row4_col0\" class=\"data row4 col0\" >3.000000</td>\n      <td id=\"T_dbd14_row4_col1\" class=\"data row4 col1\" >11.000000</td>\n      <td id=\"T_dbd14_row4_col2\" class=\"data row4 col2\" >No</td>\n      <td id=\"T_dbd14_row4_col3\" class=\"data row4 col3\" >Green</td>\n      <td id=\"T_dbd14_row4_col4\" class=\"data row4 col4\" >Calothorax lucifer</td>\n    </tr>\n    <tr>\n      <td id=\"T_dbd14_row5_col0\" class=\"data row5 col0\" >570.000000</td>\n      <td id=\"T_dbd14_row5_col1\" class=\"data row5 col1\" >75.000000</td>\n      <td id=\"T_dbd14_row5_col2\" class=\"data row5 col2\" >No</td>\n      <td id=\"T_dbd14_row5_col3\" class=\"data row5 col3\" >Black</td>\n      <td id=\"T_dbd14_row5_col4\" class=\"data row5 col4\" >Campephilus principalis</td>\n    </tr>\n  </tbody>\n</table>\n```\n:::\n:::\n\n\nThe first four columns are features, and the last column is the label. The first two features are numeric and can take on decimal values. The third feature is binary that can only be $1$ (Yes) or $0$ (No). The fourth feature is an enumeration over the color palette. You may either treat it as categorical data or numeric data, depending on how you want to build the model and what you want to get out of the data. In this example we will use it as categorical data that we only choose it from a list of colors ($1$ --- Brown, $2$ --- Gray, $3$ --- Black, $4$ --- Green). \n\nThen we are able to transform the above data into the following form:\n\n| Features | Labels | \n|-----|-----|\n| $\\begin{bmatrix}1001.1 & 125.0 & 0 & 1 \\end{bmatrix}$   | $1$    |\n| $\\begin{bmatrix}3000.7 & 200.0 & 0 & 2 \\end{bmatrix}$    | $2$    |\n| $\\begin{bmatrix}3300.0 & 220.3 & 0 & 2 \\end{bmatrix}$    | $2$  |\n| $\\begin{bmatrix}4100.0 & 136.0 & 1 & 3 \\end{bmatrix}$    | $3$    |\n| $\\begin{bmatrix}3.0 & 11.0 & 0 & 4 \\end{bmatrix}$    | $4$    |\n| $\\begin{bmatrix}570.0 & 75.0 & 0 & 3 \\end{bmatrix}$    | $5$    |\n\n: Vectorized Bird species data {#tbl-vectorized}\n\n\nThen the Supervised Learning problem is stated as follows: Given the features and the labels, we would like to find a model that can classify future data.\n\n:::\n\n\n### Parameters and hyperparameters\nA model parameter is internal to the model and its value is learned from the data. \n\nA model hyperparameter is external to the model and its value is set by people.\n\nFor example, assume that we would like to use Logistic regression to fit the data. We set the learning rate is `0.1` and the maximal iteration is `100`. After the computations are done, we get a the model \n\n$$\ny = \\sigma(0.8+0.7x).\n$$\nThe two cofficients $0.8$ and $0.7$ are the parameters of the model. The model `Logistic regression`, the learning rate `0.1` and the maximal iteration `100` are all hyperparametrs. If we change to a different set of hyperparameters, we may get a different model, with a different set of parameters.\n\nThe details of Logistic regression will be discussed later.\n\n### Evaluate a Machine Learning model\nOnce the model is built, how do we know that it is good or not? The naive idea is to test the model on some brand new data and check whether it is able to get the desired results. The usual way to achieve it is to split the input dataset into three pieces: *training set*, *validation set* and *test set*.\n\nThe model is initially fit on the training set, with some arbitrary selections of hyperparameters. Then hyperparameters will be changed, and new model is fitted over the training set. Which set of hyperparameters is better? We then test their performance over the validation set. We could run through a lot of different combinations of hyperparameters, and find the best performance over the validation set. After we get the best hyperparameters, the model is selcted, and we fit it over the training set to get our model to use.\n\nTo compare our model with our models, either our own model using other algorithms, or models built by others, we need some new data. We can no longer use the training set and the validation set since all data in them are used, either for training or for hyperparameters tuning. We need to use the test set to evaluate the \"real performance\" of our data.\n\nTo summarize: \n\n- Training set: used to fit the model;\n- Validation set: used to tune the hyperparameters;\n- Test set: used to check the overall performance of the model.\n\nThe validation set is not always required. If we use cross-validation technique for hyperparameters tuning, like `sklearn.model_selection.GridSearchCV()`, we don't need a separated validation set. In this case, we will only need the training set and the test set, and run `GridSearchCV` over the training set. The cross-validation will be discussed in {numref}`Section %s<section-cross-validation>`. \n\nThe sizes and strategies for dataset division depends on the problem and data available. It is often recommanded that more training data should be used. The typical distribution of training, validation and test is $(6:3:1)$, $(7:2:1)$ or $(8:1:1)$. Sometimes validation set is discarded and only training set and test set are used. In this case the distribution of training and test set is usually $(7:3)$, $(8:2)$ or $(9:1)$.\n\n\n### Workflow in developing a machine learning application\n\nThe workflow described below is from @Har2012.\n\n1. Collect data.\n2. Prepare the input data.\n3. Analyze the input data.\n4. Train the algorithm.\n5. Test the algorithm.\n6. Use it.\n\nIn this course, we will mainly focus on Step 4 as well Step 5. These two steps are where the \"core\" algorithms lie, depending on the algorithm. We will start from the next Chapter to talk about various Machine Learning algorithms and examples.\n\n\n<!-- \n## Output data structure\n\n### Binary Classification Problem\nWhen there are only one class, and all we care about is whether a data point belongs to this class or not, we call this type of problem **binary classification** problem. \n\nIn this case, the desired output for each data point is either $1$ or $0$, where $1$ means \"belonging to this class\" and $0$ means \"not belonging to this class\".\n\nIf there are two classes, we can still use the idea of binary classification to study the problem. We choose one class as our focus. When the data point belongs to the other class, we can simply say it does belong to the class we choose.\n\n### $0$ and $1$\nIn many cases the desired output is either $0$ or $1$, while the output of the model is a real number between $0$ and $1$. In this case, the output of the model is interpreted as the probability for the data to be in the specific class. When we use this model, we simply choose the class that has the highest probability and claim that the data is belonging to this class. \n\nIn the binary case, the above method can be stated in another way. We choose a threshold, and treat those whose probability are above the threshold to be in the class, and others not. The default value for the threshold is $0.5$, and in this case the method is just a special case for the previous method. \n\n### One-hot coding -->\n\n\n\n## Data visualization\n\nWe need to visualize the data during toying with models. We will introduce two ways for the visualization. \n\n### Naive way\n\nThe idea is to record the data we want to visualize, and then direct display the data with a certain visualization library. The most popular and default choice is `matplotlib`. Although there are many customizations, the basic usage is very simple.\n\n::: {#9fb8393a .cell execution_count=2}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\n\nx = [1, 2, 3, 4, 5]\ny = [1, 0, 4, -1, 3]\nz = [-1, 0, 3, -2, 3]\n\nplt.plot(x, y, label='y')\nplt.plot(x, z, label='z')\nplt.legend()\n```\n\n::: {.cell-output .cell-output-display}\n![](intro_files/figure-html/cell-3-output-1.png){width=569 height=411}\n:::\n:::\n\n\nSince in most cases in this course we would like to see line plot, this piece of code shows the main usage. \n\n- We need to specify two series of data as `x` and `y` respectively.\n- We could show two lines in the same plot.\n- If we add labels, and show legend, legends and labels in the plot will be automatically generated.\n\n### `Tensorboard`\n\nInstead of manually recording data and show plots, we could use logging tools for visualization. Similar to libraries, there are many tools of choice. `tensorboard` is one of simpler tools. `tensorboard` originally is a tool for `tensorflow`. It later joins `PyTorch` and becomes a (relatively independent) tool. Here we will use it with `PyTorch` since in the second half of the semester we will talk about `PyTorch`. To install `tensorboard` after you install `PyTorch` you could use the following command. More details can be found [here](https://pytorch.org/tutorials/beginner/introyt/tensorboardyt_tutorial.html). Note that `tensorboard` depends on `matplotlib` therefore they have to be installed simutanously.\n\n```{.bash}\npip install matplotlib tensorboard\n```\n\n\nThe basic idea of tensorboard is that it is logger that record the information you send to it. It can then retrieve the information and show some plots later. Whether the plots are good or not depends on how you structure the data sent to it. There are many customizations. Here we will only discuss one way to use it.\n\nThe mindset of using `tensorboard` is as follows.\n1. A logger should be initialized to accept your data. \n2. For organization, we put the logs in a foler structure.\n3. During runs, we send data to the logger.\n4. After the run, the logger is closed.\n5. We could later run `tensorboard` to load these logs to see the data we generated during runs.\n\n::: {#aa0fbf56 .cell execution_count=3}\n``` {.python .cell-code}\nfrom torch.utils.tensorboard import SummaryWriter\n\nwriter = SummaryWriter('runs/ex1')\nx = [1, 2, 3, 4, 5]\ny = [1, 0, 4, -1, 3]\nz = [-1, 0, 3, -2, 3]\n\nfor i in range(5):\n    writer.add_scalar('y', y[i], x[i])\n    writer.add_scalar('z', z[i], x[i])\n\nwriter.close()\n```\n:::\n\n\nThis piece of code shows the basic usage of `tensorboard`. \n\n1. We first initialize the logger and put it in the folder `runs/ex1`. Note that if this folder is not assigned, a folder with random name will be generated. But if the name is assigned like what we do here, the logs will be recorded in this folder everytime we run the code. This is NOT recommended. \n2. Then we use `.add_scalar` to send the data we need to the logger one by one. Note that for these scalar data the three arguments are `label`, `value` and `independent variable`. \n3. At the end, the logger will be closed and saved to disk.\n\nTo visualize the result, you may type the command in comma line, and `tensorboard` will then let you know where you can visualize the data.\n\n```{.bash}\ntensorboard --logdir=runs/ex1 \n```\n```\nTensorBoard 2.18.0 at http://localhost:6006/ (Press CTRL+C to quit)\n```\n\nClick the link, you will see tensorboard as follows.\n\n![](assests/img/20250228164959.png)\n\n\n\nHow `tensorboard` show the data depends on how you structure your data. Here I suggest a way to organize the data you send to `tensorboard`.\n\n1. Use date/time and other indicators as the name of each run.\n2. Group similar metrics together and record them in a dictionary.\n3. When using a dictionary to send many scalars, use `add_scalars` instead of `add_scalar`.\n\n::: {#4983fd44 .cell execution_count=4}\n``` {.python .cell-code}\nfrom torch.utils.tensorboard import SummaryWriter\nfrom datetime import datetime\n\nrunfolder = datetime.now().strftime('%Y%d%m-%H%M%S')\nwriter = SummaryWriter(f'runs/{runfolder}')\nx = [1, 2, 3, 4, 5]\ny = [1, 0, 4, -1, 3]\nz = [-1, 0, 3, -2, 3]\n\nfor i in range(5):\n    scalars = {\n        'y': y[i],\n        'z': z[i]\n    }\n    writer.add_scalars('scalars', scalars, x[i])\n\nwriter.close()\n```\n:::\n\n\n![](assests/img/20250228170146.png)\n\n\n\n::: {.callout-note}\nNote that the plots from `tensorboard` and `matplotlib` are a little different. The reason is that `tensorboard` automatically smooth the curve. You can use the cmoothing factor to control the effect. When you change it to be 0, you will get exactly the same plot.\n:::\n\n\n\n\n## Python quick guide\n\n### Python Notebook\nWe mainly use Python Notebook (.ipynb) to write documents for this course. Currently all main stream Python IDE support Python Notebook. All of them are not entirely identical but the differences are not huge and you may choose any you like.\n\nOne of the easiest ways to use Python Notebook is through [JupyterLab](https://jupyter.org/try). The best part about it is that you don't need to worry about installation and configuration in the first place, and you can directly start to code. \n\nClick the above link and choose JupyterLab. Then you will see the following page. \n\n![](assests/img/20220727120418.png)  \n\nThe webapp you just started is called JupyterLite. This is a demo version. The full JupyterLab installation instruction can also be found from the link.\n\n\nThere is a small button `+` under the tab bar. This is the place where you click to start a new cell. You may type codes or markdown documents or raw texts in the cell according to your needs. The drag-down menu at the end of the row which is named `Code` or `Markdown` or `Raw` can help you make the switch. Markdown is a very simple light wighted language to write documents. In most cases it behaves very similar to plain texts. Codes are just regular Python codes (while some other languages are supported). You may either use the triangle button in the menu to execute the codes, or hit `shift + enter`. \n\n![](assests/img/20220727120505.png)  \nJupyterLite contains a few popular packages. Therefore it is totally ok if you would like to play with some simple things. However since it is an online evironment, it has many limitations. Therefore it is still recommended to set up a local environment once you get familiar with Python Notebook. Please check the following links for some popular choices for notebooks and Python installations in general, either local and online.\n\n- [Jupyter Notebook / JupyterLab](https://jupyter.org/install)\n- [VS Code](https://code.visualstudio.com/docs/languages/python)\n- [PyCharm](https://www.jetbrains.com/help/pycharm/jupyter-notebook-support.html)\n- [Google Colab](https://colab.research.google.com/)\n- [Anaconda](https://www.anaconda.com/)\n\n\n### Python fundamentals\nWe will put some very basic Python commands here for you to warm up. More advanced Python knowledge will be covered during the rest of the semester. The main reference for this part is @Har2012. Another referenece is [My notes](https://xiaoxl.github.io/pr24/).\n\n#### Indentation\nPython is using indentation to denote code blocks. It is not convienent to write in the first place, but it forces you to write clean, readable code.\n\nBy the way, the `if` and `for` block are actually straightforward.\n\n:::{layout-nrow=2}\n\n::: {#78ae1803 .cell execution_count=5}\n``` {.python .cell-code}\nif jj < 3:\n    jj = jj \n    print(\"It is smaller than 3.\")\n```\n:::\n\n\n::: {#9e6f7914 .cell execution_count=6}\n``` {.python .cell-code}\nif jj < 3:\n    jj = jj\nprint(\"It is smaller than 3.\")\n```\n:::\n\n\n::: {#52b9d75d .cell execution_count=7}\n``` {.python .cell-code}\nfor i in range(3):\n    i = i + 1\n    print(i)\n```\n:::\n\n\n::: {#8a30289f .cell execution_count=8}\n``` {.python .cell-code}\nfor i in range(3):\n    i = i + 1\nprint(i)\n```\n:::\n\n\n:::\n\n\nPlease tell the differences between the above codes.\n\n\n#### `list` and `dict`\nHere are some very basic usage of lists of dictionaries in Python.\n\n::: {#5ca6c003 .cell execution_count=9}\n``` {.python .cell-code}\nnewlist = list()\nnewlist.append(1)\nnewlist.append('hello')\nnewlist\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\n[1, 'hello']\n```\n:::\n:::\n\n\n::: {#cc652a38 .cell execution_count=10}\n``` {.python .cell-code}\nnewlisttwo = [1, 'hello']\nnewlisttwo\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\n[1, 'hello']\n```\n:::\n:::\n\n\n::: {#b39b9711 .cell execution_count=11}\n``` {.python .cell-code}\nnewdict = dict()\nnewdict['one'] = 'good'\nnewdict[1] = 'yes'\nnewdict\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\n{'one': 'good', 1: 'yes'}\n```\n:::\n:::\n\n\n::: {#aa996311 .cell execution_count=12}\n``` {.python .cell-code}\nnewdicttwo = {'one': 'good', 1: 'yes'}\nnewdicttwo\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\n{'one': 'good', 1: 'yes'}\n```\n:::\n:::\n\n\n#### Loop through lists\nWhen creating `for` loops we may let Python directly loop through lists. Here is an example. The code is almost self-explained.\n\n::: {#ecde449a .cell execution_count=13}\n``` {.python .cell-code}\nalist = ['one', 2, 'three', 4]\n\nfor item in alist:\n    print(item)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\none\n2\nthree\n4\n```\n:::\n:::\n\n\n#### Reading files\nThere are a lot of functions that can read files. The basic one is to read any files as a big string. After we get the string, we may parse it based on the structure of the data.\n\nThe above process sounds complicated. That's why we have so many different functions reading files. Usually they focus on a certain types of files (e.g. spreadsheets, images, etc..), parse the data into a particular data structure for us to use later.\n\nI will mention a few examples.\n\n- `csv` files and `excel` files\nBoth of them are spreadsheets format. Usually we use [`pandas.read_csv`](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) and [`pandas.read_excel`](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html) both of which are from the package `pandas` to read these two types of files. \n\n- images\n    Images can be treated as matrices, that each entry represents one pixel. If the image is black/white, it is represented by one matrix where each entry represents the gray value. If the image is colored, it is represented by three matrices where each entry represents one color. To use which three colors depends on the color map. `rgb` is a popular choice. \n\n    In this course when we need to read images, we usually use [`matplotlib.pyplot.imread`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imread.html) from the package `matplotlib` or [`cv.imread`](https://docs.opencv.org/4.x/d4/da8/group__imgcodecs.html#ga288b8b3da0892bd651fce07b3bbd3a56) from the package `opencv`.\n\n- `.json` files\n`.json` is a file format to store dictionary type of data. To read a `json` file and parse it as a dictionary, we need [`json.load`](https://docs.python.org/3/library/json.html#json.load) from the package `json`. \n\n#### Writing files\n\n- [`pandas.DataFrame.to_csv`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html)\n- [`pandas.DataFrame.to_excel`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_excel.html)\n- [`matplotlib.pyplot.imsave`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imsave.html)\n- [`cv.imwrite`](https://docs.opencv.org/3.4/d4/da8/group__imgcodecs.html#gabbc7ef1aa2edfaa87772f1202d67e0ce)\n- [`json.dump`](https://docs.python.org/3/library/json.html#json.dump)\n\n#### Relative paths\nIn this course, when reading and writing files, please keep all the files using relative paths. That is, only write the path starting from the working directory. \n\n\n::: {#exm-}\n\n\nConsider the following tasks:\n\n1. Your working directory is `C:/Users/Xinli/projects/`.\n2. Want to read a file `D:/Files/example.csv`.\n3. Want to generate a file whose name is `result.csv` and put it in a subfoler named `foldername`.\n\nTo do the tasks, don't directly run the code `pd.read_csv('D:/Files/example.csv')`. Instead you should first copy the file to your working directory `C:/Users/Xinli/projects/`, and then run the following code. \n\n::: {#7f7a9482 .cell execution_count=14}\n``` {.python .cell-code}\nimport pandas as pd\n\ndf = pd.read_csv('example.csv')\ndf.to_csv('foldername/result.csv')\n```\n:::\n\n\nPlease pay attention to how the paths are written.\n\n\n:::\n\n\n#### `.`\n\n- class and packages.\n- Get access to attributes and methods\n- Chaining dots.\n\n### Some additional topics\n\nYou may read about these parts from the appendices of [My notes](https://xiaoxl.github.io/pr23f/contents/app/virtenv.html).\n\n#### Package management and Virtual environment\n\n- [`conda`](https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html)\n  - `conda create`\n    - `conda create --name myenv` \n    - `conda create --name myenv python=3.9` \n    - `conda create --name myenv --file spec-file.txt`\n  - `conda install`\n    - `conda install -c conda-forge numpy`\n  - `conda activate myenv`\n  - `conda list`\n    - `conda list numpy`\n    - `conda list --explicit > spec-file.txt`\n  - `conda env list`\n- `pip` / [`venv`](https://docs.python.org/3/library/venv.html)\n  - `python -m venv newenv`\n  - `newenv\\Scripts\\activate`\n  - `pip install`\n  - `pip freeze > requirements.txt`\n  - `pip install -r /path/to/requirements.txt`\n  - `deactivate`\n\n#### Version Control\n\n- `Git`\n  - [Install](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)\n  - `git config --list`\n  - `git config --global user.name \"My Name\"`\n  - `git config --global user.email \"myemail@example.com\"`\n- `GitHub`\n\n\n\n## Exercises \nThese exercises are from @Klo2021, @Ger2019 and @Har2012. \n\n### Python Notebook\n\n\n::: {#exr-helloworld}\n\n# Hello World!\n\nPlease set up a Python Notebook environment and type `print('Hello World!')`.\n:::\n\n::: {#exr-}\nPlease set up a Python Notebook and start a new virtual environment and type `print('Hello World!')`.\n:::\n\n### Basic Python \n\n\n::: {#exr-ex1helloworld}\n\n# Play with lists\n\nPlease complete the following tasks.\n\n- Write a `for` loop to print values from 0 to 4.\n- Combine two lists `['apple', 'orange']` and `['banana']` using `+`.\n- Sort the list `['apple', 'orange', 'banana']` using `sorted()`.\n:::\n<!-- \n````{solution} ex1helloworld\n:class: dropdown\n\n```{code-block} python\nfor i in range(5):\n    print(i)\n\nnewlist = ['apple', 'orange'] + ['banana']\n\nsorted(['apple', 'orange', 'banana'])\n```\n\nPlease be careful about the last line. `sorted()` doesn't change the original list. It create a new list. There are some Python functions which change the inputed object in-place. Please read documents on all packages you use to get the desired results.\n```` -->\n\n:::{#exr-ex1list}\n# Play with list, dict and pandas.\n\n\nPlease complete the following tasks.\n\n- Create a new dictionary `people` with two keys `name` and `age`. The values are all empty list.\n- Add `Tony` to the `name` list in `people`. \n- Add `Harry` to the `name` list in `people`.\n- Add number 100 to the `age` list in `people`.\n- Add number 10 to the `age` list in `people`.\n- Find all the keys of `people` and save them into a list `namelist`.\n- Convert the dictionary `people` to a Pandas DataFrame `df`.\n:::\n\n<!-- ````{solution} ex1list\n:class: dropdown\n```{code-block} python\nimport pandas as pd\n\npeople = {'name': list(), 'age': list()}\npeople['name'].append('Tony')\npeople['name'].append('Harry')\npeople['age'].append(100)\npeople['age'].append(10)\n\nnamelist = people.keys()\n\ndf = pd.DataFrame(people)\n```\n```` -->\n\n\n\n:::{#exr-ex1iris}\n# The dataset iris\n\n::: {#13ae094d .cell execution_count=15}\n``` {.python .cell-code}\nfrom sklearn.datasets import load_iris\niris = load_iris()\n```\n:::\n\n\nPlease explore this dataset.\n\n- Please get the features for `iris` and save it into `X` as an numpy array.\n- What is the meaning of these features?\n- Please get the labels for `iris` and save it into `y` as an numpy array.\n- What is the meaning of labels?\n:::\n\n<!-- ````{solution} ex1iris\n:class: dropdown\nWe first find that `iris` is a dictionary. Then we can look at all the keys by `iris.keys()`. The interesting keys are `data`, `target`, `target_names` and `feature_names`. We can also read the description of the dataset by looking at `DESCR`. \n```{code-block} python\nX = iris['data']\nprint(iris['feature_names'])\ny = iris['target']\nprint(iris['target'])\n```\nSince the data is already saved as numpy arrays, we don't need to do anything to change its type.\n```` -->\n\n:::{#exr-ex1pandastitanic}\n# Play with Pandas\n\nPlease download the Titanic data file from [here](./assests/datasets/titanic.csv). Then follow the instructions to perform the required tasks.\n\n- Use `pandas.read_csv` to read the dataset and save it as a dataframe object `df`.\n- Change the values of the `Sex` column that `male` is `0` and `female` is `1`. \n- Pick the columns `Pclass`, `Sex`, `Age`, `Siblings/Spouses Aboard`, `Parents/Children Aboard` and `Fare` and transform them into a 2-dimensional `numpy.ndarray`, and save it as `X`.\n- Pick the column `Survived` and transform it into a 1-dimensional `numpy.ndarray` and save it as `y`.\n:::\n\n<!-- ````{solution} ex1pandastitanic\n:class: dropdown\n\nNot yet done!\n```` -->\n\n",
    "supporting": [
      "intro_files\\figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}