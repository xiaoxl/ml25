{
  "hash": "ce50176432922347f5942dd6e7bfb2b9",
  "result": {
    "engine": "jupyter",
    "markdown": "# k-Nearest Neighbors algorithm (k-NN)\nThis algorithm is different from other algorithms covered in this course, that it doesn't really extract features from the data. However, since its idea is easy to understand, we use it as our first step towards machine learning world.\n\nSimilar to other algorithms, we will only cover the beginning part of the algorithm. All later upgrades of the algorithms are left for yourselves to learn.\n\nReferences: @Har2012.\n\n\n\n\n\n\n## k-Nearest Neighbors Algorithm (k-NN)\n\n### Ideas\nAssume that we have a set of labeled data $\\{(X_i, y_i)\\}$ where $y_i$ denotes the label. Given a new data $X$, how do we determine the label of it? \n\nk-NN algorithm starts from a very straightforward idea. We use the distances from the new data point $X$ to the known data points to identify the label. If $X$ is closer to $y_i$ points, then we will label $X$ as $y_i$. \n\nLet us take cities and countries as an example. <span style=\"color:red\">New York</span> and <span style=\"color:red\">Los Angeles</span> are U.S cities, and <span style=\"color:grey\">Beijing</span> and <span style=\"color:grey\">Shanghai</span> are Chinese cities. Now we would like to consider Tianjin and Russellville. Do they belong to China or U.S? We calculate the distances from Tianjin (resp. Russellville) to all four known cities. Since Tianjin is closer to <span style=\"color:grey\">Beijing</span> and <span style=\"color:grey\">Shanghai</span> comparing to <span style=\"color:red\">New York</span> and <span style=\"color:red\">Los Angeles</span>, we classify Tianjin as a Chinese city. Similarly, since Russellville is closer to <span style=\"color:red\">New York</span> and <span style=\"color:red\">Los Angeles</span> comparing to <span style=\"color:grey\">Beijing</span> and <span style=\"color:grey\">Shanghai</span>, we classify it as a U.S. city.\n\n\n\n\n\n\n```{dot}\ndigraph G {\n    layout=circo\n\n    Beijing [color=black]\n    Shanghai [color=black]\n    Tianjin [color=blue, fontcolor=black, shape=box]\n\n    \"New York\" [color=red, fontcolor=red]\n    \"Los Angelis\" [color=red, fontcolor=red]\n    Russellville [color=blue, fontcolor=red, shape=box]\n\n\n \n    Tianjin -> Beijing [label=\"closer\"];\n    Tianjin -> Shanghai [label=\"closer   \"];\n    Tianjin -> \"New York\" [style=dashed, color=blue, fontcolor=blue, label=\" far away\"];\n    Tianjin -> \"Los Angelis\" [style=dashed, color=blue, fontcolor=blue, label=\" far away\"];\n    Russellville -> \"New York\" [color=red, label=\"closer  \", fontcolor=red];\n    Russellville -> \"Los Angelis\" [color=red, label=\"closer\", fontcolor=red];\n    Russellville -> Beijing [color=red, style=dashed, color=blue, label=\"far away \", fontcolor=blue];\n    Russellville -> Shanghai [color=red, style=dashed, color=blue, label=\"far away\", fontcolor=blue];\n}\n```\n\n\n\n\nThis naive example explains the idea of k-NN. Here is a more detailed description of the algorithm. \n\n### The Algorithm\n\n\n\n::: {.callout-note}\n# k-NN Classifier\n\n**Inputs**: Given the training data set $\\{(X_i, y_i)\\}$ where $X_i=(x_i^1,x_i^2,\\ldots,x_i^n)$ represents $n$ features and $y_i$ represents labels. Given a new data point $\\tilde{X}=(\\tilde{x}^1,\\tilde{x}^2,\\ldots,\\tilde{x}^n)$.\n\n**Outputs**: Want to find the best label for $\\tilde{X}$.\n\n1. Compute the distance from $\\tilde{X}$ to each $X_i$.\n2. Sort all these distances from the nearest to the furthest. \n3. Find the nearest $k$ data points.\n4. Determine the labels for each of these $k$ nearest points, and compute the frenqucy of each labels.\n5. The most frequent label is considered to be the label of $\\tilde{X}$.\n\n:::\n\n### Details\n- The distance between two data points are defined by the Euclidean distance:\n  \n$$\ndist\\left((x^j_i)_{j=1}^n, (\\tilde{x}^j)_{j=1}^n\\right)=\\sqrt{\\sum_{j=1}^n(x^j_i-\\tilde{x}^j)^2}.\n$$\n  \n- Using linear algebra notations: \n  \n$$\ndist(X_i,\\tilde{X})=\\sqrt{(X_i-\\tilde{X})\\cdot(X_i-\\tilde{X})}.\n$$\n\n- All the distances are stored in a $1$-dim numpy array, and we will combine it together with another $1$-dim array that store the labels of each point.\n\n### The codes\n\n\n<details>\n<summary>This part is optional.</summary>\n\n\n\n- `argsort`\n- `unique`\n- `argmax`\n\n::: {#ae237f99 .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\n\ndef classify_kNN(inX, X, y, k=5):\n    # compute the distance between each row of X and Xmat\n    Dmat = np.sqrt(((inX - X)**2).sum(axis=1))\n    # sort by distance\n    k = min(k, Dmat.shape[0])\n    argsorted = Dmat.argsort()[:k]\n    relatedy = y[argsorted]\n    # count the freq. of the first k labels\n    labelcounts = np.unique(relatedy, return_counts=True)\n    # find the label with the most counts\n    label = labelcounts[0][labelcounts[1].argmax()]\n    return label\n```\n:::\n\n\n</details>\n\n### `sklearn` packages\nYou may also directly use the kNN function `KNeighborsClassifier` packaged in `sklearn.neighbors`. You may check the description of the function online from [here](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html).\n\nThere are many ways to modify the kNN algorithm. What we just mentioned is the simplest idea. It is correspondent to the argument `weights='uniform'`, `algorithm='brute` and `metric='euclidean'`. However due to the implementation details, the results we got from `sklearn` are still a little bit different from the results produced by our naive codes.\n\n::: {#8c775047 .cell execution_count=2}\n``` {.python .cell-code}\nfrom sklearn.neighbors import KNeighborsClassifier\nclf = KNeighborsClassifier(n_neighbors=10, weights='uniform',\n                           algorithm='brute', metric='euclidean')\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\n```\n:::\n\n\n### Normalization\nDifferent features may have different scales. It might be unfair for those features that have small scales. Therefore usually it is better to rescale all the features to make them have similar scales. After examining all the data, we find the minimal value `minVal` and the range `ranges` for each column. The normalization formula is:\n\n$$\nX_{norm} = \\frac{X_{original}-minVal}{ranges}.\n$$\n\nWe could also convert the normalized number back to the original value by \n\n$$\nX_{original} = X_{norm} \\times ranges + minVal.\n$$\n\n\n\n\n<details>\n<summary>The sample codes are listed below. This part is optional.</summary>\n\n::: {#ea28c4d9 .cell execution_count=3}\n``` {.python .cell-code}\nimport numpy as np\n\ndef encodeNorm(X, parameters=None):\n    # parameters contains minVals and ranges\n    if parameters is None:\n        minVals = np.min(X, axis=0)\n        maxVals = np.max(X, axis=0)\n        ranges = np.maximum(maxVals - minVals, np.ones(minVals.size))\n        parameters = {'ranges': ranges, 'minVals': minVals}\n    else:\n        minVals = parameters['minVals']\n        ranges = parameters['ranges']\n    Nmat = np.tile(minVals, (X.shape[0], 1))\n    Xnorm = (X - Nmat)/ranges\n    return (Xnorm, parameters)\n\n\ndef decodeNorm(X, parameters):\n    # parameters contains minVals and ranges\n    ranges = parameters['ranges']\n    minVals = parameters['minVals']\n    Nmat = np.tile(minVals, (X.shape[0], 1))\n    Xoriginal = X * ranges + Nmat\n    return Xoriginal\n```\n:::\n\n\n</details>\n\nYou could use `MinMaxScaler` from `sklearn.preprocessing` to achive the goal. The API is very similar to an estimator.\n\n::: {#f7345f88 .cell execution_count=4}\n``` {.python .cell-code}\nfrom sklearn.preprocessing import MinMaxScaler\n\nmm = MinMaxScaler()\nmm.fit(X)\nX_norm = mm.transform(X)\n```\n:::\n\n\nThe last two lines can be combined into \n\n::: {#61274905 .cell execution_count=5}\n``` {.python .cell-code}\nX_norm = mm.fit_transform(X)\n```\n:::\n\n\n## k-NN Project 1: `iris` Classification\n\nThis data is from `sklearn.datasets`. This dataset consists of 3 different types of irises' petal / sepal length / width, stored in a $150\\times4$ `numpy.ndarray`. We already explored the dataset briefly in the previous chapter. This time we will try to use the feature provided to predict the type of the irises. For the purpose of plotting, we will only use the first two features: `sepal length` and `sepal width`.\n\n### Explore the dataset\nWe first load the dataset. \n\n::: {#cce7cfaa .cell execution_count=6}\n``` {.python .cell-code}\nfrom sklearn import datasets\niris = datasets.load_iris()\nX = iris.data[:, :2]\ny = iris.target\n```\n:::\n\n\nThen we would like to split the dataset into trainning data and test data. Here we are going to use `sklearn.model_selection.train_test_split` function. Besides the dataset, we should also provide the propotion of the test set comparing to the whole dataset. We will choose `test_size=0.1` here, which means that the size of the test set is 0.1 times the size of the whole dataset. `stratify=y` means that when split the dataset we want to split respects the distribution of labels in `y`. \n\nThe split will be randomly. You may set the argument `random_state` to be a certain number to control the random process. If you set a `random_state`, the result of the random process will stay the same. This is for reproducible output across multiple function calls.\n\n\nAfter we get the training set, we should also normalize it. All our normalization should be based on the training set. When we want to use our model on some new data points, we will use the same normalization parameters to normalize the data points in interests right before we apply the model. Here since we mainly care about the test set, we could normalize the test set at this stage.\n\nNote that in the following code, we mainly use the implementation from `sklearn`. \n<!-- the function `encodeNorm` defined in the previous section is used.  -->\n<!-- I import it from `assests.codes.knn`. You need to modify this part based on your file structure. See @sec-applyourknn for more details. -->\n\n::: {#9c48e10f .cell execution_count=7}\n``` {.python .cell-code}\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1, stratify=y)\n\nmm = MinMaxScaler()\nX_train_norm = mm.fit_transform(X_train)\nX_test_norm = mm.transform(X_test)\n```\n:::\n\n\nBefore we start to play with k-NN, let us look at the data first. Since we only choose two features, it is able to plot these data points on a 2D plane, with different colors representing different classes. \n\n::: {#510f7853 .cell execution_count=8}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Plot the scatter plot.\nfig = plt.figure(figsize=(10,7))\nax = fig.add_subplot(111)\nscatter = ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train)\n\n# Generate legends.\nlabels = ['setosa', 'versicolor', 'virginica']\n_ = fig.legend(handles=scatter.legend_elements()[0], labels=labels,\n               loc=\"right\", title=\"Labels\")\n```\n\n::: {.cell-output .cell-output-display}\n![](intro_files/figure-html/cell-9-output-1.png){width=883 height=560}\n:::\n:::\n\n\n### Apply our k-NN model {#sec-applyourknn}\n\nNow let us apply k-NN to this dataset. Since our data is prepared, what we need to do is directly call the functions.\n\n::: {#ac64639c .cell execution_count=9}\n``` {.python .cell-code}\nfrom sklearn.neighbors import KNeighborsClassifier\nn_neighbors = 10\nclf = KNeighborsClassifier(n_neighbors, weights=\"uniform\", metric=\"euclidean\",\n                           algorithm='brute')\nclf.fit(X_train_norm, y_train)\ny_pred_sk = clf.predict(X_test_norm)\n\nacc = np.mean(y_pred_sk == y_test)\nacc\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\nnp.float64(0.7333333333333333)\n```\n:::\n:::\n\n\n### Using data pipeline\nWe may organize the above process in a neater way. After we get a data, the usual process is to apply several transforms to the data before we really get to the model part. Using terminolgies from `sklearn`, the former are called *transforms*, and the latter is called an *estimator*. In this example, we have exactly one tranform which is the normalization. The estimator here we use is the k-NN classifier. \n\n`sklearn` provides a standard way to write these codes, which is called `pipeline`. We may chain the transforms and estimators in a sequence and let the data go through the pipeline. In this example, the pipeline contains two steps:\n1. The normalization transform `sklearn.preprocessing.MinMaxScaler`. \n2. The k-NN classifier `sklearn.neighbors.KNeighborsClassifier`. This is the same one as we use previously.\n\nThe code is as follows. It is a straightforward code. Note that the `()` after the class in each step of `steps` is very important. The codes cannot run if you miss it.\n\nAfter we setup the pipeline, we may use it as other estimators since it is an estimator. Here we may also use the accuracy function provided by `sklearn` to perform the computation. It is essentially the same as our `acc` computation.\n\n::: {#35fe6ebd .cell execution_count=10}\n``` {.python .cell-code}\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import accuracy_score\n\nn_neighbors = 10\nsteps = [('scaler', MinMaxScaler()),\n         ('knn', KNeighborsClassifier(n_neighbors, weights=\"uniform\",\n                                      metric=\"euclidean\", algorithm='brute'))]\npipe = Pipeline(steps=steps)\npipe.fit(X_train, y_train)\ny_pipe = pipe.predict(X_test)\naccuracy_score(y_pipe, y_test)\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\n0.7333333333333333\n```\n:::\n:::\n\n\nOnce a pipeline is set, you may use `step name` with TWO underscores `__` with `parameter name` to get access to a specific parameter. Please check the following code.\n\n::: {#21c3ff73 .cell execution_count=11}\n``` {.python .cell-code}\npipe.get_params()['knn__n_neighbors']\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\n10\n```\n:::\n:::\n\n\n::: {#41ca7408 .cell execution_count=12}\n``` {.python .cell-code}\npipe.set_params(knn__n_neighbors=5)\npipe.get_params()['knn__n_neighbors']\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\n5\n```\n:::\n:::\n\n\n### Visualize the Decision boundary\n\n<details>\n<summary>This section is optional.</summary>\n\nUsing the classifier we get above, we are able to classify every points on the plane. This enables us to draw the following plot, which is called the Decision boundary. It helps us to visualize the relations between features and the classes.\n\nWe use `DecisionBoundaryDisplay` from `sklearn.inspection` to plot the decision boundary. The function requires us to have a fitted classifier. We may use the classifier `pipe` we got above. Note that this classifier should have some build-in structures that our `classify_kNN` function doesn't have. We may rewrite our codes to make it work, but this goes out of the scope of this section. This is supposed to be Python programming exercise. We will talk about it in the future if we have enough time.\n\nWe first plot the dicision boundary using `DecisionBoundaryDisplay.from_estimator`. Then we plot the points from `X_test`. From the plot it is very clear which points are misclassified.\n\n::: {#08edd169 .cell execution_count=13}\n``` {.python .cell-code}\nfrom sklearn.inspection import DecisionBoundaryDisplay\n\ndisp = DecisionBoundaryDisplay.from_estimator(\n            pipe, \n            X_train,\n            response_method=\"predict\",\n            plot_method=\"pcolormesh\",\n            xlabel=iris.feature_names[0],\n            ylabel=iris.feature_names[1],\n            alpha=0.5)\ndisp.ax_.scatter(X_test[:, 0], X_test[:, 1], c=y_test, edgecolor=\"k\")\ndisp.figure_.set_size_inches((10,7))\n```\n\n::: {.cell-output .cell-output-display}\n![](intro_files/figure-html/cell-14-output-1.png){width=812 height=577}\n:::\n:::\n\n\n</details>\n\n### k-Fold Cross-Validation {#sec-cross-validation}\n\nPreviously we perform a random split and test our model in this case. What would happen if we fit our model on another split? We might get a different accuracy score. So in order to evaluate the performance of our model, it is natual to consider several different split and compute the accuracy socre for each case, and combine all these socres together to generate an index to indicate whehter our model is good or bad. This naive idea is called *k-Fold Cross-Validation*.\n\nThe algorithm is described as follows. We first randomly split the dataset into `k` groups of the same size. We use one of them as the test set, and the rest together forming the training set, and use this setting to get an accuracy score. We did this for each group to be chosen as the test set. Then the final score is the mean.\n\n\n::: {.callout-note collapse=\"true\"}\n# `KFold`\n`KFold` from `sklearn.model.selection` is used to split the dataset into `k` groups and in each iteration to chooose one as the validation set. \n\n::: {#e2d2f6f9 .cell execution_count=14}\n``` {.python .cell-code}\nfrom sklearn.model_selection import KFold\n\nkf = KFold(n_splits=5)\n\nfor train_idx, val_idx in kf.split(range(10)):\n    print(train_idx, val_idx)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[2 3 4 5 6 7 8 9] [0 1]\n[0 1 4 5 6 7 8 9] [2 3]\n[0 1 2 3 6 7 8 9] [4 5]\n[0 1 2 3 4 5 8 9] [6 7]\n[0 1 2 3 4 5 6 7] [8 9]\n```\n:::\n:::\n\n\n- I only put `range(10)` in `kf.split` since it only needs to work with the index. If a dataset is put there, the output is still the index of which data is in the training set and which is in the validation set.\n- If you want to randomize the selection, when set up `KFold` we could add an argument `shuffle=True`. In this case, we may use `random_state` to control the outcome provide reproducing ability.\n\nLet us see an example for our data.\n\n::: {#f5d3ceb3 .cell execution_count=15}\n``` {.python .cell-code}\nfrom sklearn.model_selection import KFold\nfrom sklearn.base import clone\n\nkf = KFold(n_splits=5, shuffle=True, random_state=1)\n\ncv_scores = []\nfor train_idx, val_idx in kf.split(X):\n    pipe_tmp = clone(pipe)\n    pipe_tmp.fit(X[train_idx], y[train_idx])\n    cv_scores.append(pipe_tmp.score(X[val_idx], y[val_idx]))\ncv_scores\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```\n[0.8333333333333334,\n 0.7333333333333333,\n 0.7333333333333333,\n 0.7,\n 0.7666666666666667]\n```\n:::\n:::\n\n\n::: {#ae606cd3 .cell execution_count=16}\n``` {.python .cell-code}\nnp.mean(cv_scores)\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\nnp.float64(0.7533333333333333)\n```\n:::\n:::\n\n\nNote that here `sklearn.base.clone` is used to initialize an unfitted model which has the same hyperpamaters as `pipe`.\n\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n# `cross_validate`\n`KFold` is too \"manual\". We may use `cross_validate` to autmate the above process. Note that depending on the arguments given `cross_validate` may be implemented by `KFold`.\n\n::: {#868ed984 .cell execution_count=17}\n``` {.python .cell-code}\nfrom sklearn.model_selection import cross_validate\n\ncv_result = cross_validate(pipe, X, y, cv=5, scoring='accuracy')\ncv_result\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\n{'fit_time': array([0.0030055 , 0.00227547, 0.00099826, 0.00199318, 0.00199986]),\n 'score_time': array([0.00800037, 0.0065515 , 0.0082345 , 0.00600076, 0.0079999 ]),\n 'test_score': array([0.73333333, 0.8       , 0.76666667, 0.9       , 0.73333333])}\n```\n:::\n:::\n\n\nAnd you may only see the scores if this is the only thing that interests you.\n\n::: {#57db2516 .cell execution_count=18}\n``` {.python .cell-code}\ncv_result['test_score']\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n```\narray([0.73333333, 0.8       , 0.76666667, 0.9       , 0.73333333])\n```\n:::\n:::\n\n\n- You may choose different scoring methods. More info can be found in [the document](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter).\n- If `cv=5`, `KFold(5, shuffle=False)` is applied here. If you prefer random split, you may directly use `KFold` here.\n\n::: {#3d86da5e .cell execution_count=19}\n``` {.python .cell-code}\ncv_result = cross_validate(pipe, X, y, scoring='accuracy',\n                           cv=KFold(5, shuffle=True, random_state=1))\ncv_result['test_score']\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```\narray([0.83333333, 0.73333333, 0.73333333, 0.7       , 0.76666667])\n```\n:::\n:::\n\n\nYou may compare this result with the previous one and the one in `KFold` section.\nOf course, the cv score is usually the mean of all the scores.\n\n::: {#2d305f96 .cell execution_count=20}\n``` {.python .cell-code}\ncv_result['test_score'].mean()\n```\n\n::: {.cell-output .cell-output-display execution_count=17}\n```\nnp.float64(0.7533333333333333)\n```\n:::\n:::\n\n\n:::\n\n::: {.callout-note collapse=\"true\"}\n# `cross_val_score`\nThis is a faster way to directly get `cv_result['test_score']` in `cross_validate` section. The argument about `cv` and `scoring` are the same as `cross_validate`.\n\n::: {#840355fa .cell execution_count=21}\n``` {.python .cell-code}\nfrom sklearn.model_selection import cross_val_score\ncv_scores = cross_val_score(pipe, X, y, cv=KFold(5, shuffle=True, random_state=1))\ncv_scores\n```\n\n::: {.cell-output .cell-output-display execution_count=18}\n```\narray([0.83333333, 0.73333333, 0.73333333, 0.7       , 0.76666667])\n```\n:::\n:::\n\n\n::: {#e3effc90 .cell execution_count=22}\n``` {.python .cell-code}\ncv_scores.mean()\n```\n\n::: {.cell-output .cell-output-display execution_count=19}\n```\nnp.float64(0.7533333333333333)\n```\n:::\n:::\n\n\n:::\n\n\n\n### Choosing a `k` value\nIn the previous example we choose `k` to be `10` as an example. To choose a `k` value we usually run some test by trying different `k` and choose the one with the best performance. In this case, best performance means the highest cross-validation score.\n\n\n\n\n::: {.callout-note collapse=\"true\"}\n# Grid search\n\n`sklearn.model_selection.GridSearchCV` provides a way to do this directly. We only need to setup the esitimator, the metric (which is the cross-validation score in this case), and the hyperparameters to be searched through, and `GridSearchCV` will run the search automatically.\n\nWe let `k` go from `1` to `100`. The code is as follows.\n\nNote that `parameters` is where we set the search space. It is a dictionary. The key is the name of the estimator plus double `_` and then plus the name of the parameter. \n\n::: {#01efabc0 .cell execution_count=23}\n``` {.python .cell-code}\nfrom sklearn.model_selection import GridSearchCV\nn_list = list(range(1, 101))\nparameters = dict(knn__n_neighbors=n_list)\nclf = GridSearchCV(pipe, parameters)\nclf.fit(X, y)\nclf.best_estimator_.get_params()[\"knn__n_neighbors\"]\n```\n\n::: {.cell-output .cell-output-display execution_count=20}\n```\n35\n```\n:::\n:::\n\n\nAfter we fit the data, the `best_estimator_.get_params()` can be printed. It tells us that it is best to use `31` neibhours for our model. We can directly use the best estimator by calling `clf.best_estimator_`.\n\n::: {#cc2afece .cell execution_count=24}\n``` {.python .cell-code}\ncv_scores = cross_val_score(clf.best_estimator_, X, y, cv=5)\nnp.mean(cv_scores)\n```\n\n::: {.cell-output .cell-output-display execution_count=21}\n```\nnp.float64(0.82)\n```\n:::\n:::\n\n\nThe cross-validation score using `k=31` is calculated. This serves as a benchmark score and we may come back to dataset using other methods and compare the scores.\n:::\n\n\n\n::: {.callout-note collapse=\"true\"}\n# Plot the curve\nGrid search can only give us a single number that has the best cross validation score. However there are many cases that the number might not be really the best. So usually we also want to see the result for all `k`. The best way to display all results simutanously is to plot the curve.\n\n::: {#ee31141a .cell execution_count=25}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\n\nn_list = list(range(1, 101))\ncv_scores = []\nfor k in n_list:\n    pipe_tmp = clone(pipe)\n    pipe_tmp.set_params(knn__n_neighbors=k)\n    cv_scores.append(cross_val_score(pipe_tmp, X, y, cv=5).mean())\n\nplt.plot(cv_scores)\n```\n\n::: {.cell-output .cell-output-display}\n![](intro_files/figure-html/cell-26-output-1.png){width=579 height=411}\n:::\n:::\n\n\nFrom this plot, combining with the best cv score happens at `k=31`, we could make our final decision about which `k` to choose.\n\n:::\n\n\n## k-NN Project 2: Dating Classification\n\nThe data can be downloaded from [here](./assests/datasets/datingTestSet2.txt).\n\n\n### Background\nHelen dated several people and rated them using a three-point scale: 3 is best and 1 is worst. She also collected data from all her dates and recorded them in the file attached. These data contains 3 features:\n\n- Number of frequent flyer miles earned per year\n- Percentage of time spent playing video games\n- Liters of ice cream consumed per week\n\nWe would like to predict her ratings of new dates when we are given the three features. \n\nThe data contains four columns, while the first column refers to `Mileage`, the second `Gamingtime`, the third `Icecream` and the fourth `Rating`. \n\n### Look at Data\n\nWe first load the data and store it into a DataFrame.\n\n::: {#ff5c0231 .cell execution_count=26}\n\n::: {.cell-output .cell-output-display execution_count=23}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>40920</td>\n      <td>8.326976</td>\n      <td>0.953952</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14488</td>\n      <td>7.153469</td>\n      <td>1.673904</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>26052</td>\n      <td>1.441871</td>\n      <td>0.805124</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>75136</td>\n      <td>13.147394</td>\n      <td>0.428964</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>38344</td>\n      <td>1.669788</td>\n      <td>0.134296</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {#23d0ed0a .cell execution_count=27}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf = pd.read_csv('datingTestSet2.txt', sep='\\t', header=None)\ndf.head()\n```\n:::\n\n\nTo make it easier to read, we would like to change the name of the columns.\n\n::: {#fd4f5ad6 .cell execution_count=28}\n``` {.python .cell-code}\ndf = df.rename(columns={0: \"Mileage\", 1: \"Gamingtime\", 2: 'Icecream', 3: 'Rating'})\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=24}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mileage</th>\n      <th>Gamingtime</th>\n      <th>Icecream</th>\n      <th>Rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>40920</td>\n      <td>8.326976</td>\n      <td>0.953952</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14488</td>\n      <td>7.153469</td>\n      <td>1.673904</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>26052</td>\n      <td>1.441871</td>\n      <td>0.805124</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>75136</td>\n      <td>13.147394</td>\n      <td>0.428964</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>38344</td>\n      <td>1.669788</td>\n      <td>0.134296</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nSince now we have more than 2 features, it is not suitable to directly draw scatter plots. We use `seaborn.pairplot` to look at the pairplot. From the below plots, before we apply any tricks, it seems that `Milegae` and `Gamingtime` are better than `Icecream` to classify the data points. \n\n::: {#fb799020 .cell execution_count=29}\n``` {.python .cell-code}\nimport seaborn as sns\nsns.pairplot(data=df, hue='Rating')\n```\n\n::: {.cell-output .cell-output-display}\n![](intro_files/figure-html/cell-30-output-1.png){width=774 height=709}\n:::\n:::\n\n\n### Applying kNN\n\nSimilar to the previous example, we will apply both methods for comparisons. \n\n::: {#552acca9 .cell execution_count=30}\n``` {.python .cell-code}\nfrom sklearn.model_selection import train_test_split\nX = np.array(df[['Mileage', 'Gamingtime', 'Icecream']])\ny = np.array(df['Rating'])\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=40, stratify=y)\n```\n:::\n\n\n::: {#3ba7d282 .cell execution_count=31}\n``` {.python .cell-code}\n# Using sklearn.\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\n\nsteps = [('scaler', MinMaxScaler()),\n         ('knn', KNeighborsClassifier(n_neighbors, weights=\"uniform\",\n                                      metric=\"euclidean\", algorithm='brute'))]\npipe = Pipeline(steps=steps)\npipe.fit(X_train, y_train)\ny_pipe = pipe.predict(X_test)\naccuracy_score(y_pipe, y_test)\n```\n\n::: {.cell-output .cell-output-display execution_count=27}\n```\n0.93\n```\n:::\n:::\n\n\n### Choosing `k` Value\nSimilar to the previous section, we can run tests on `k` value to choose one to be used in our model using `GridSearchCV`.\n\n::: {#1c924cb1 .cell execution_count=32}\n``` {.python .cell-code}\nfrom sklearn.model_selection import GridSearchCV\nn_list = list(range(1, 101))\nparameters = dict(knn__n_neighbors=n_list)\nclf = GridSearchCV(pipe, parameters, cv=5)\nclf.fit(X_train, y_train)\nclf.best_estimator_.get_params()[\"knn__n_neighbors\"]\n```\n\n::: {.cell-output .cell-output-display execution_count=28}\n```\n12\n```\n:::\n:::\n\n\n::: {#7922be1f .cell execution_count=33}\n``` {.python .cell-code}\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.base import clone\nimport matplotlib.pyplot as plt\n\nn_list = list(range(1, 101))\ncv_scores = []\nfor k in n_list:\n    pipe_tmp = clone(pipe)\n    pipe_tmp.set_params(knn__n_neighbors=k)\n    cv_scores.append(cross_val_score(pipe_tmp, X_train, y_train, cv=5).mean())\nplt.plot(cv_scores)\n```\n\n::: {.cell-output .cell-output-display}\n![](intro_files/figure-html/cell-34-output-1.png){width=588 height=411}\n:::\n:::\n\n\nFrom this result, in this case the best `k` is `12`. The corresponding test score is \n\n::: {#faa266ea .cell execution_count=34}\n``` {.python .cell-code}\nclf.score(X_test, y_test)\n```\n\n::: {.cell-output .cell-output-display execution_count=30}\n```\n0.93\n```\n:::\n:::\n\n\n## k-NN Project 3: Handwritten recognition\n\nWe would like to let the machine recognize handwritten digits. The dataset is MNIST comeing from the [MNIST database](https://yann.lecun.com/exdb/mnist/). Now we apply kNN algrotithm to it. \n\n### Dataset description\nEvery digit is stored as a $28\\times28$ picture. This is a $28\\times28$ matrix. Every entry represents a gray value of the corresponding pixel, whose value is from 0 to 255. The label of each matrix is the digit it represents. Note that the dataset provided is already splitted into a training set and a test set.\n\nThe dataset can be loaded following the [instruction](https://xiaoxl.github.io/Datasets/contents/mnist.html).\n\n::: {#90e20cd4 .cell execution_count=35}\n``` {.python .cell-code}\nfrom datasets import load_dataset\nimport numpy as np\nimport itertools\n\ndef pil_to_array(data):\n    data['image'] = np.array(data['image'])\n    return data\n\nmnist_train = load_dataset(\"ylecun/mnist\", split='train').take(600)\nmnist_test = load_dataset(\"ylecun/mnist\", split='test').take(100)\n\nmnist_train_processed = mnist_train.map(pil_to_array)\nmnist_test_processed = mnist_test.map(pil_to_array)\n\nX_train = np.array(mnist_train_processed['image']).reshape(-1, 784)\ny_train = np.array(mnist_train_processed['label']).reshape(-1)\nX_test = np.array(mnist_test_processed['image']).reshape(-1, 784)\ny_test = np.array(mnist_test_processed['label']).reshape(-1)\n```\n:::\n\n\nNote that one of the purpose to load the data in streaming mode is that the dataset is big and it is not wise to load everything all together. However this is the only way to train a KNN model since all it does is to memorize everything. In the future with other models we may want to load the image one by one with the streaming mode.\n\nAlso due to the issue of large dataset, I only choose the first 600/100 images from the original dataset. This is implemented by the `.take` method when loading the dataset.\n\n::: {#c82dab94 .cell execution_count=36}\n``` {.python .cell-code}\nnp.unique(y_train, return_counts=True)\n```\n\n::: {.cell-output .cell-output-display execution_count=32}\n```\n(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n array([58, 79, 64, 59, 59, 51, 54, 62, 49, 65]))\n```\n:::\n:::\n\n\nAlthough not optimal, all digits are presented, and the distributions are relatively equal. So we will use this slice of the original dataset. In reality, if possible it is always better to use all data provided to you.\n\n\n\n\n### Apply k-NN\nLike the previous two examples, we now try to apply the k-NN algorithm to classify these handwritten digits. Note that the original dataset is huge and the processing time is very slow. However since we only choose 600/100 images, we could still run all our tricks. \n\n::: {#da7afc36 .cell execution_count=37}\n``` {.python .cell-code}\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.base import clone\nimport matplotlib.pyplot as plt\n\nsteps = [('scaler', MinMaxScaler()),\n         ('knn', KNeighborsClassifier(n_neighbors=5))]\npipe = Pipeline(steps=steps)\nn_list = list(range(1, 11))\n\ncv_score = []\nfor k in n_list:\n    pipe_tmp = clone(pipe)\n    pipe_tmp.set_params(knn__n_neighbors=k)\n    cv_score.append(cross_val_score(pipe_tmp, X_train, y_train, cv=5).mean())\nplt.plot(n_list, cv_score)\n```\n\n::: {.cell-output .cell-output-display}\n![](intro_files/figure-html/cell-38-output-1.png){width=579 height=411}\n:::\n:::\n\n\n::: {#5950fc10 .cell execution_count=38}\n``` {.python .cell-code}\nfrom sklearn.model_selection import GridSearchCV\n\ngs = GridSearchCV(pipe, param_grid=dict(knn__n_neighbors=n_list), cv=5)\ngs.fit(X_train, y_train)\ngs.best_params_\n```\n\n::: {.cell-output .cell-output-display execution_count=34}\n```\n{'knn__n_neighbors': 3}\n```\n:::\n:::\n\n\nThe best `k` is 3 for this degenerated dataset. The corresponding test score is \n\n::: {#ec3bb385 .cell execution_count=39}\n``` {.python .cell-code}\ngs.score(X_test, y_test)\n```\n\n::: {.cell-output .cell-output-display execution_count=35}\n```\n0.82\n```\n:::\n:::\n\n\n## Exercises and Projects\n\n\n::: {#exr-ex2handwritten}\n\nHandwritten example\n:label: ex2handwritten\nConsider the 1-dimensional data set shown below.\n\n::: {#3de26d95 .cell execution_count=40}\n\n::: {.cell-output .cell-output-display execution_count=36}\n```{=html}\n<style type=\"text/css\">\n</style>\n<table id=\"T_23bc7\">\n  <thead>\n    <tr>\n      <th id=\"T_23bc7_level0_col0\" class=\"col_heading level0 col0\" >x</th>\n      <th id=\"T_23bc7_level0_col1\" class=\"col_heading level0 col1\" >1.5</th>\n      <th id=\"T_23bc7_level0_col2\" class=\"col_heading level0 col2\" >2.5</th>\n      <th id=\"T_23bc7_level0_col3\" class=\"col_heading level0 col3\" >3.5</th>\n      <th id=\"T_23bc7_level0_col4\" class=\"col_heading level0 col4\" >4.5</th>\n      <th id=\"T_23bc7_level0_col5\" class=\"col_heading level0 col5\" >5.0</th>\n      <th id=\"T_23bc7_level0_col6\" class=\"col_heading level0 col6\" >5.5</th>\n      <th id=\"T_23bc7_level0_col7\" class=\"col_heading level0 col7\" >5.75</th>\n      <th id=\"T_23bc7_level0_col8\" class=\"col_heading level0 col8\" >6.5</th>\n      <th id=\"T_23bc7_level0_col9\" class=\"col_heading level0 col9\" >7.5</th>\n      <th id=\"T_23bc7_level0_col10\" class=\"col_heading level0 col10\" >10.5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td id=\"T_23bc7_row0_col0\" class=\"data row0 col0\" >y</td>\n      <td id=\"T_23bc7_row0_col1\" class=\"data row0 col1\" >+</td>\n      <td id=\"T_23bc7_row0_col2\" class=\"data row0 col2\" >+</td>\n      <td id=\"T_23bc7_row0_col3\" class=\"data row0 col3\" >-</td>\n      <td id=\"T_23bc7_row0_col4\" class=\"data row0 col4\" >-</td>\n      <td id=\"T_23bc7_row0_col5\" class=\"data row0 col5\" >-</td>\n      <td id=\"T_23bc7_row0_col6\" class=\"data row0 col6\" >+</td>\n      <td id=\"T_23bc7_row0_col7\" class=\"data row0 col7\" >+</td>\n      <td id=\"T_23bc7_row0_col8\" class=\"data row0 col8\" >-</td>\n      <td id=\"T_23bc7_row0_col9\" class=\"data row0 col9\" >+</td>\n      <td id=\"T_23bc7_row0_col10\" class=\"data row0 col10\" >+</td>\n    </tr>\n  </tbody>\n</table>\n```\n:::\n:::\n\n\nPlease use the data to compute the class of $x=5.5$ according to $k=1$, $3$, $6$ and $9$. Please compute everything by hand.\n\n:::\n\n\n::: {#exr-ex2titanic}\n# Titanic \nPlease download the titanic dataset from [here](./assests/datasets/titanic.csv). This is the same dataset from what you dealt with in Chapter 1 Exercises. Therefore you may use the same way to prepare the data. \n\nPlease analyze the dataset and build a k-NN model to predict whether someone is survived or not. Note that you have to pick `k` at the end.\n:::\n\n",
    "supporting": [
      "intro_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}